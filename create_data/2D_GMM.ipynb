{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.distributions as D\n",
    "from functools import partial\n",
    "import os\n",
    "import json\n",
    "from copy import deepcopy\n",
    "\n",
    "from pinf.plot.utils import eval_pdf_on_grid_2D\n",
    "from pinf.models.GMM import GMM\n",
    "from pinf.datasets.gradients import dS_dbeta_2D_GMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Settings\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_new = True\n",
    "n_samples = 500000\n",
    "bs = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the target distribution\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = torch.tensor([\n",
    "    [-1.0,2.0],\n",
    "    [3.0,7.0],\n",
    "    [-4.0,2.0],\n",
    "    [-2.0,-4.0],\n",
    "    [0.0,4.0],\n",
    "    [5.0,-2.0]\n",
    "])\n",
    "\n",
    "#Covariance matrices\n",
    "S = torch.tensor([\n",
    "        [[ 0.2778,  0.4797],\n",
    "         [ 0.4797,  0.8615]],\n",
    "\n",
    "        [[ 0.8958, -0.0249],\n",
    "         [-0.0249,  0.1001]],\n",
    "\n",
    "        [[ 1.3074,  0.9223],\n",
    "         [ 0.9223,  0.7744]],\n",
    "\n",
    "        [[ 0.0305,  0.0142],\n",
    "         [ 0.0142,  0.4409]],\n",
    "\n",
    "        [[ 0.0463,  0.0294],\n",
    "         [ 0.0294,  0.3441]],\n",
    "        \n",
    "        [[ 0.15,  0.0294],\n",
    "         [ 0.0294,  1.5]]])\n",
    "\n",
    "p_target = GMM(means = means,covs=S)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_beta(x,beta,Z = None):\n",
    "    q_beta = p_target(x).pow(beta)\n",
    "\n",
    "    if Z is None:\n",
    "        return q_beta\n",
    "    \n",
    "    else:\n",
    "        return q_beta / Z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approximate the partition function of the power-scaled distribution\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_list = torch.linspace(np.log(0.1),np.log(10),20).exp()\n",
    "T_list = torch.cat((T_list,torch.tensor([1.0])))\n",
    "T_list = T_list.sort().values\n",
    "\n",
    "\n",
    "if generate_new:\n",
    "\n",
    "  fig,axes = plt.subplots(1,len(T_list),figsize = (30,15))\n",
    "\n",
    "  Z_T_list = []\n",
    "\n",
    "  for i,T in enumerate(T_list):\n",
    "      p = partial(p_beta,beta = 1 / round(T_list[i].item(),5))\n",
    "\n",
    "      pdf_grid,x_grid,y_grid = eval_pdf_on_grid_2D(\n",
    "        pdf=p,\n",
    "        x_lims = [-15,15],\n",
    "        y_lims = [-15,15],\n",
    "        x_res = 10000,\n",
    "        y_res = 10000,\n",
    "        )\n",
    "      \n",
    "      # Get the volume element\n",
    "      dA = (x_grid[0,1] - x_grid[0,0]) * (y_grid[1,0] - y_grid[0,0])\n",
    "\n",
    "      # Get the partition function\n",
    "      Z_T = pdf_grid.sum() * dA\n",
    "      Z_T_list.append(Z_T)\n",
    "      print(Z_T)\n",
    "      \n",
    "      axes[i].imshow(pdf_grid,extent = [x_grid.min(),x_grid.max(),y_grid.min(),y_grid.max()],origin = 'lower')\n",
    "\n",
    "      axes[i].set_title(f'T = {round(T_list[i].item(),5)}')\n",
    "      axes[i].axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"../data/2D_GMM\"\n",
    "\n",
    "if generate_new:\n",
    "\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "\n",
    "    dict_Z_T = {\n",
    "    }\n",
    "\n",
    "    for i in range(len(T_list)):\n",
    "        dict_Z_T[f\"{round(T_list[i].item(),5)}\"] = Z_T_list[i].item()\n",
    "\n",
    "    with open(os.path.join(folder,'Z_T.json'), 'w') as f:\n",
    "        json.dump(dict_Z_T, f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform rejection sampling\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConcatenatedGMM(GMM):\n",
    "    def __init__(self,means:torch.tensor,covs:torch.tensor,sigma_noise:float,weights:torch.tensor = None)->None:\n",
    "\n",
    "        #Compute new covariance matrices\n",
    "\n",
    "        for i in range(len(means)):\n",
    "            \n",
    "            covs[i] = covs[i] + torch.eye(2) * sigma_noise**2\n",
    "        \n",
    "        super().__init__(means = means,covs = covs,weights = weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if generate_new:\n",
    "\n",
    "    if not os.path.exists(os.path.join(folder,\"validation_data/\")):\n",
    "        os.makedirs(os.path.join(folder,\"validation_data/\"))\n",
    "\n",
    "    if not os.path.exists(os.path.join(folder,\"training_data/\")):\n",
    "        os.makedirs(os.path.join(folder,\"training_data/\"))\n",
    "\n",
    "    for i in range(len(T_list)):\n",
    "\n",
    "        if T_list[i] > 1.0:\n",
    "            p_prop = ConcatenatedGMM(means = means,covs = deepcopy(S),sigma_noise = 2.0)\n",
    "        else:\n",
    "            p_prop = GMM(means = means,covs = deepcopy(S))\n",
    "\n",
    "        def p_beta(x,beta,Z = None):\n",
    "            p_GMM_plain = GMM(means = means,covs = deepcopy(S))\n",
    "            q_beta = p_GMM_plain(x).pow(beta)\n",
    "\n",
    "            if Z is None:\n",
    "                return q_beta\n",
    "            \n",
    "            else:\n",
    "                return q_beta / Z\n",
    "\n",
    "        p_eval = partial(p_beta,beta = 1 / round(T_list[i].item(),5),Z = Z_T_list[i])\n",
    "\n",
    "        samples_i = torch.zeros([0,2])\n",
    "\n",
    "        while True:\n",
    "\n",
    "            #Get u\n",
    "            u = torch.rand(bs)\n",
    "\n",
    "            #get proposals\n",
    "            x_prop = p_prop.sample(bs)\n",
    "\n",
    "            r = p_eval(x_prop) / (p_prop(x_prop) * 10)\n",
    "\n",
    "            accept = u < r\n",
    "\n",
    "            samples_i = torch.cat((samples_i,x_prop[accept]),dim = 0)\n",
    "           \n",
    "            if len(samples_i) > n_samples:\n",
    "                break\n",
    "        \n",
    "        torch.save(samples_i[:int(0.8 * n_samples)],os.path.join(folder,f'training_data/T_{round(T_list[i].item(),5)}_dim_2.pt'))\n",
    "        torch.save(samples_i[int(0.8 * n_samples):],os.path.join(folder,f'validation_data/T_{round(T_list[i].item(),5)}_dim_2.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the empirical distribution to the target distribution \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(2,len(T_list),figsize = (len(T_list) * 15,2 * 15))\n",
    "with open(os.path.join(folder,'Z_T.json'), 'r') as f:\n",
    "  dict_Z_T = json.load(f)\n",
    "f.close()\n",
    "\n",
    "for i,T in enumerate(T_list):\n",
    "\n",
    "    T_i = round(T.item(),5)\n",
    "\n",
    "    #Ground truth distribution\n",
    "    p = partial(p_beta,beta = 1 / round(T_list[i].item(),5), Z = dict_Z_T[f\"{round(T_list[i].item(),5)}\"])\n",
    "\n",
    "    pdf_grid,x_grid,y_grid = eval_pdf_on_grid_2D(\n",
    "        pdf=p,\n",
    "        x_lims = [-15,15],\n",
    "        y_lims = [-15,15],\n",
    "        x_res = 150,\n",
    "        y_res = 150,\n",
    "    )\n",
    "      \n",
    "    axes[0][i].imshow(pdf_grid,extent = [x_grid.min(),x_grid.max(),y_grid.min(),y_grid.max()],origin = 'lower')\n",
    "\n",
    "    axes[0][i].set_title(f'T = {round(T_list[i].item(),5)}')\n",
    "    axes[0][i].axis('off')\n",
    "    axes[0][i].set_title(T_i)\n",
    "\n",
    "\n",
    "    #Empirical distribution based on the samples\n",
    "    data_val_i = torch.load(os.path.join(folder,f'training_data/T_{T_i}_dim_2.pt'))\n",
    "\n",
    "    x = data_val_i[:,0].numpy()\n",
    "    y = data_val_i[:,1].numpy()\n",
    "\n",
    "    h,_, _, image = axes[1][i].hist2d(x,y,bins = 150, density = True,range = [[-15,15],[-15,15]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the expectation value of the energy\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_eval = torch.linspace(0.5,2.0,200)\n",
    "res_expectation_val = 1500\n",
    "lim_expectation_approx = 25\n",
    "EX_A_storage = []\n",
    "\n",
    "pdf_grid,x_grid,y_grid = eval_pdf_on_grid_2D(\n",
    "    pdf=p_target,\n",
    "    x_lims = [-lim_expectation_approx,lim_expectation_approx],\n",
    "    y_lims = [-lim_expectation_approx,lim_expectation_approx],\n",
    "    x_res = res_expectation_val,\n",
    "    y_res = res_expectation_val,\n",
    "    )\n",
    "\n",
    "dV = (x_grid[0,1] - x_grid[0,0]) * (y_grid[1,0] - y_grid[0,0])\n",
    "\n",
    "dS_dparam = partial(dS_dbeta_2D_GMM,gmm = p_prop,beta = 1.0,device = \"cpu\")\n",
    "\n",
    "A,_,_ = eval_pdf_on_grid_2D(\n",
    "        pdf= dS_dparam,\n",
    "        x_lims = [-lim_expectation_approx,lim_expectation_approx],\n",
    "        y_lims = [-lim_expectation_approx,lim_expectation_approx],\n",
    "        x_res = res_expectation_val,\n",
    "        y_res = res_expectation_val,\n",
    "        )\n",
    "\n",
    "for i,beta_i in enumerate(beta_eval):\n",
    "    \n",
    "    #Get the partition function\n",
    "    Z_i = pdf_grid.pow(beta_i).sum() * dV\n",
    "    EX_A = (A * pdf_grid.pow(beta_i) * dV / Z_i).sum()\n",
    "\n",
    "    EX_A_storage.append(EX_A)\n",
    "\n",
    "data = np.concatenate((beta_eval.reshape(-1,1),np.array(EX_A_storage).reshape(-1,1)),1)\n",
    "\n",
    "np.savetxt(os.path.join(folder,\"EX_A_ground_truth.txt\"),data,header = \"beta\\tEX_S\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(beta_eval,EX_A_storage)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pinf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
