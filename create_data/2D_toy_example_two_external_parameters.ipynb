{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from functools import partial\n",
    "import os\n",
    "import json\n",
    "\n",
    "from pinf.models.GMM import GMM\n",
    "from pinf.plot.utils import eval_pdf_on_grid_2D\n",
    "from pinf.datasets.log_likelihoods import log_p_2D_ToyExample_two_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Settings\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\"\n",
    "generate_new = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target distribution\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_alpha_beta(x,alpha,beta,device,Z = None):\n",
    "    return log_p_2D_ToyExample_two_parameters(\n",
    "        x = x,\n",
    "        parameter_list=[alpha,beta],\n",
    "        device = device,\n",
    "        Z = Z).exp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the distributions and approximate the partition function\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_list = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "beta_list = [0.2,0.25,1/3,0.5,1.0,2.0,3.0,4.0,5.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"../data/2D_Toy_two_external_parameters\"\n",
    "\n",
    "if generate_new:\n",
    "\n",
    "   fig,axes = plt.subplots(len(alpha_list),len(beta_list),figsize = (5 * len(beta_list),5 * len(alpha_list)))\n",
    "\n",
    "   Z_dict = {}\n",
    "\n",
    "   for i,alpha in enumerate(alpha_list):\n",
    "      for j,beta in enumerate(beta_list):\n",
    "        \n",
    "         p_ij = partial(p_alpha_beta,alpha = alpha,beta = round(beta,5),device = device)\n",
    "\n",
    "         pdf_grid,x_grid,y_grid = eval_pdf_on_grid_2D(\n",
    "            pdf=p_ij,\n",
    "            x_lims = [-17,17],\n",
    "            y_lims = [-17,17],\n",
    "            x_res = 10000,\n",
    "            y_res = 10000,\n",
    "            )\n",
    "      \n",
    "         #Get the volume element\n",
    "         dA = (x_grid[0,1] - x_grid[0,0]) * (y_grid[1,0] - y_grid[0,0])\n",
    "\n",
    "         #Get the partition function\n",
    "         Z_ij = pdf_grid.sum() * dA\n",
    "        \n",
    "         Z_dict[f\"alpha_{alpha}_beta_{round(beta,5)}\"] = Z_ij.item()\n",
    "         \n",
    "         axes[i][j].imshow(pdf_grid,extent = [x_grid.min(),x_grid.max(),y_grid.min(),y_grid.max()],origin = 'lower',cmap = \"jet\")\n",
    "\n",
    "         axes[i][j].set_title(f'a = {alpha}, b = {round(beta,5)}')\n",
    "         axes[i][j].axis('off')\n",
    "\n",
    "   if not os.path.exists(folder):\n",
    "      os.makedirs(folder)\n",
    "\n",
    "   with open(os.path.join(folder,'Z_dict.json'), 'w') as f:\n",
    "      json.dump(Z_dict, f)\n",
    "   f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform rejection sampling sampling\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConcatenatedGMM(GMM):\n",
    "    def __init__(self,means:torch.tensor,covs:torch.tensor,sigma_noise:float,weights:torch.tensor = None,device = None)->None:\n",
    "\n",
    "        #Compute new covariance matrices\n",
    "\n",
    "        for i in range(len(means)):\n",
    "            \n",
    "            covs[i] = covs[i] + torch.eye(2) * sigma_noise**2\n",
    "\n",
    "        super().__init__(means = means,covs = covs,weights = weights,device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_1 = torch.tensor([[1.0,-0.5],[-0.5,7.0]])\n",
    "S_2 = torch.tensor([[1.0,0.5],[0.5,7.0]])\n",
    "\n",
    "m_1 = torch.tensor([-4.0,0.0])\n",
    "m_2 = torch.tensor([4.0,0.0])\n",
    "\n",
    "with open(os.path.join(folder,'Z_dict.json'), 'r') as f:\n",
    "    Z_dict = json.load(f)\n",
    "f.close()\n",
    "\n",
    "if generate_new:\n",
    "    n_samples = 500000\n",
    "    bs = 10000\n",
    "\n",
    "    for i,alpha in enumerate(alpha_list):\n",
    "        for j,beta in enumerate(beta_list):\n",
    "\n",
    "            #Get the proposal distribution, use condatenation with gaussian in case of beta < 1.0 for better tail sampling\n",
    "            if beta < 1.0:\n",
    "                p_prop = ConcatenatedGMM(\n",
    "                    means = [m_1,m_2],\n",
    "                    covs = [S_1,S_2],\n",
    "                    device = device,\n",
    "                    weights = torch.tensor([alpha,1.0 - alpha]),\n",
    "                    sigma_noise = 3.0\n",
    "                )\n",
    "\n",
    "            else:\n",
    "                p_prop = GMM(\n",
    "                    means = [m_1,m_2],\n",
    "                    covs = [S_1,S_2],\n",
    "                    device = device,\n",
    "                    weights = torch.tensor([alpha,1.0 - alpha])\n",
    "                )\n",
    "\n",
    "            p_eval = partial(p_alpha_beta,alpha = alpha,beta = round(beta,5),Z = Z_dict[f\"alpha_{alpha}_beta_{round(beta,5)}\"],device = device)\n",
    "            \n",
    "            samples_i = torch.zeros([0,2])\n",
    "\n",
    "            while True:\n",
    "\n",
    "                #Get u\n",
    "                u = torch.rand(bs)\n",
    "\n",
    "                #get proposals\n",
    "                x_prop = p_prop.sample(bs)\n",
    "\n",
    "                r = p_eval(x_prop) / (p_prop(x_prop) * 100)\n",
    "\n",
    "                accept = u < r\n",
    "\n",
    "                samples_i = torch.cat((samples_i,x_prop[accept]),dim = 0)\n",
    "\n",
    "                if len(samples_i) > n_samples:\n",
    "                    break\n",
    "\n",
    "            #Save the results\n",
    "            if os.path.exists(os.path.join(folder,\"validation_data/\")) == False:\n",
    "                os.makedirs(os.path.join(folder,\"validation_data/\"))\n",
    "         \n",
    "            if os.path.exists(os.path.join(folder,\"training_data/\")) == False:\n",
    "                os.makedirs(os.path.join(folder,\"training_data/\"))\n",
    "           \n",
    "            torch.save(samples_i[:int(0.8 * n_samples)],os.path.join(folder,f'training_data/alpha_{alpha}_beta_{round(beta,5)}_dim_2.pt'))\n",
    "            torch.save(samples_i[int(0.8 * n_samples):],os.path.join(folder,f'validation_data/alpha_{alpha}_beta_{round(beta,5)}_dim_2.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot samples\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(len(alpha_list),len(beta_list),figsize = (5 * len(beta_list),5 * len(alpha_list)))\n",
    "\n",
    "for i,alpha in enumerate(alpha_list):\n",
    "    for j,beta in enumerate(beta_list):\n",
    "\n",
    "        data_val_i = torch.load(os.path.join(folder,f'validation_data/alpha_{alpha}_beta_{round(beta,5)}_dim_2.pt'))\n",
    "\n",
    "        axes[i,j].scatter(data_val_i[:,0],data_val_i[:,1],s = 0.1)\n",
    "        axes[i,j].set_title(f'alpha = {alpha} = beta_{round(beta,5)}')\n",
    "        axes[i,j].axis('off')\n",
    "        axes[i,j].set_xlim(-17,17)\n",
    "        axes[i,j].set_ylim(-17,17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot Empirical distribution of the samples\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(len(alpha_list),len(beta_list),figsize = (5 * len(beta_list),5 * len(alpha_list)))\n",
    "\n",
    "for i,alpha in enumerate(alpha_list):\n",
    "    for j,beta in enumerate(beta_list):\n",
    "\n",
    "        data_train_i = torch.load(os.path.join(folder,f'training_data/alpha_{alpha}_beta_{round(beta,5)}_dim_2.pt'))\n",
    "\n",
    "        _ = axes[i,j].hist2d(data_train_i[:,0].numpy(),data_train_i[:,1].numpy(),bins = 150, density = True,range = [[-15,15],[-15,15]],cmap = \"jet\")\n",
    "        axes[i,j].set_title(f'alpha = {alpha} = beta_{round(beta,5)}')\n",
    "        axes[i,j].axis('off')\n",
    "        axes[i,j].set_xlim(-17,17)\n",
    "        axes[i,j].set_ylim(-17,17)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pinf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
