{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from functools import partial\n",
    "import json\n",
    "\n",
    "from utils import (\n",
    "    get_validation_loader_dict_2D_GMM,\n",
    "    load_INN,\n",
    "    p_beta\n",
    ")\n",
    "\n",
    "from pinf.plot.utils import eval_pdf_on_grid_2D\n",
    "from pinf.models.GMM import GMM\n",
    "from pinf.datasets.parameters import (\n",
    "    means_2D_GMM,\n",
    "    S_2D_GMM\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda:0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the validation data\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_list = torch.linspace(np.log(0.1),np.log(10),20).exp()\n",
    "T_list = torch.cat((T_list,torch.tensor([1.0])))\n",
    "T_list = [round(T_list.sort().values[i].item(),5) for i in range(len(T_list))]\n",
    "\n",
    "a = 7\n",
    "T_list_eval = T_list[10 - a:-(10 - a)]\n",
    "\n",
    "validation_data_loader_dict = get_validation_loader_dict_2D_GMM(T_list_eval = T_list_eval,n_samples = 80000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the paths to the trained models\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path_TRADE_grid =          \"../../results/runs_2D_GMM/<Your experiment name>/lightning_logs/version_0/\"\n",
    "base_path_TRADE_no_grid =       \"../../results/runs_2D_GMM/<Your experiment name>/lightning_logs/version_0/\"\n",
    "base_path_reverse_KL =          \"../../results/runs_2D_GMM/<Your experiment name>/lightning_logs/version_0/\"\n",
    "base_path_reverse_KL_nll =      \"../../results/runs_2D_GMM/<Your experiment name>/lightning_logs/version_0/\"\n",
    "base_path_nll_only =            \"../../results/runs_2D_GMM/<Your experiment name>/lightning_logs/version_0/\"\n",
    "base_path_reweighting =         \"../../results/runs_2D_GMM/<Your experiment name>/lightning_logs/version_0/\"\n",
    "base_path_volume_preserving =   \"../../results/runs_2D_GMM/<Your experiment name>/lightning_logs/version_0/\"\n",
    "\n",
    "base_paths_dict = {\n",
    "    \"TRADE_grid\":base_path_TRADE_grid,\n",
    "    \"TRADE_no_grid\":base_path_TRADE_no_grid,\n",
    "    \"nll_only\":base_path_nll_only,\n",
    "    \"reverse_KL\":base_path_reverse_KL,\n",
    "    \"reverse_KL_nll\":base_path_reverse_KL_nll,\n",
    "    \"reweighting\":base_path_reweighting,\n",
    "    \"volume preserving\":base_path_volume_preserving\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the models\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INN_dict = {}\n",
    "config_dict = {}\n",
    "for key in base_paths_dict:\n",
    "    INN_k,config_k = load_INN(base_path = base_paths_dict[key],device=device,use_last=False)\n",
    "    INN_dict[key] = INN_k\n",
    "    config_dict[key] = config_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the validation nll\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gmm = GMM(means = means_2D_GMM,covs=S_2D_GMM,device=device)\n",
    "\n",
    "with open(\"../../data/2D_GMM/Z_T.json\",\"r\") as f:\n",
    "    Z_T_dict = json.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_KLD_dicts = {}\n",
    "error_val_KLD_dicts = {}\n",
    "\n",
    "n_bootstrap = 20\n",
    "\n",
    "for T_i in T_list_eval:\n",
    "    val_KLD_dicts[f\"{T_i}\"] = {}\n",
    "    error_val_KLD_dicts[f\"{T_i}\"] = {}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for k in INN_dict:\n",
    "        print(\"evaluate \",k)\n",
    "\n",
    "        for T_i in T_list_eval:\n",
    "            T_i = round(T_i,5)\n",
    "            \n",
    "            DL_i = validation_data_loader_dict[f\"{T_i}\"]\n",
    "\n",
    "            log_p_theta_val = torch.zeros([0])\n",
    "            log_p_gt_val = torch.zeros([0])\n",
    "\n",
    "            for j,(beta_batch,x_batch) in enumerate(DL_i):\n",
    "                \n",
    "                # Model log likelihood\n",
    "                log_p_theta_val_i = INN_dict[k].log_prob(x_batch.to(device),beta_tensor=beta_batch.to(device))\n",
    "                log_p_theta_val = torch.cat((log_p_theta_val,log_p_theta_val_i.detach().cpu()),0)\n",
    "\n",
    "                # Ground truth log likelihood\n",
    "                log_p_gt_val_i = p_beta(x_batch.to(device),beta = 1 / T_i,gmm = gmm,Z = Z_T_dict[f\"{T_i}\"]).log()\n",
    "                log_p_gt_val = torch.cat((log_p_gt_val,log_p_gt_val_i.detach().cpu()),0)\n",
    "\n",
    "            assert(log_p_gt_val.shape == log_p_theta_val.shape)\n",
    "            \n",
    "            # Apply bootstrapping to estimate the deviation of the evaluation nlls\n",
    "            samples = np.zeros(n_bootstrap)\n",
    "\n",
    "            for i in range(n_bootstrap):\n",
    "                indices = np.random.randint(0,len(log_p_theta_val),len(log_p_theta_val))\n",
    "            \n",
    "                samples[i] = (log_p_gt_val[indices] - log_p_theta_val[indices]).mean()\n",
    "\n",
    "            mean_samples = samples.mean()\n",
    "            error_i = np.sqrt(np.square(samples - mean_samples).sum() / (n_bootstrap - 1))\n",
    "            error_val_KLD_dicts[f\"{T_i}\"][k] = error_i    \n",
    "\n",
    "            # Get the log likelihood of the validation set\n",
    "            val_KLD_i = (log_p_gt_val - log_p_theta_val).mean().item()\n",
    "            val_KLD_dicts[f\"{T_i}\"][k] = val_KLD_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Latex table\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#T_print = [0.20691,0.33598,0.54556]#,0.88587,1.0,1.12884,1.83298,2.97635,4.83293]\n",
    "#T_print = [0.88587,1.0,1.12884]\n",
    "T_print = [1.83298,2.97635,4.83293]\n",
    "\n",
    "row_name_dict = {\n",
    "    \"nll_only\":\"NLL + lat. TS\",\n",
    "    \"TRADE_grid\":\"TRADE (grid)\",\n",
    "    \"TRADE_no_grid\":\"TRADE (no grid)\",\n",
    "    \"reverse_KL\":\"Reverse KLD\",\n",
    "    \"reverse_KL_nll\":\"NLL + Reverse KLD\",\n",
    "    \"reweighting\":\"Reweighting\",\n",
    "    \"volume preserving\":\"Volume Preserving\",\n",
    "    \"gt\":\"Ground Truth\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best value in each colume:\n",
    "is_best_dict = {}\n",
    "\n",
    "for T_i in T_print:\n",
    "\n",
    "    is_best_dict[f\"{T_i}\"] = {}\n",
    "\n",
    "    min_key = None\n",
    "\n",
    "    for k in INN_dict:\n",
    "        is_best_dict[f\"{T_i}\"][k] = False\n",
    "\n",
    "        if (min_key is None) or (val_KLD_dicts[f'{T_i}'][k] < val_KLD_dicts[f'{T_i}'][min_key]):\n",
    "            min_key = k\n",
    "\n",
    "    is_best_dict[f\"{T_i}\"][min_key] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highlight_color = \"lightgray\"\n",
    "rows_to_highlight = [\"TRADE_grid\",\"TRADE_no_grid\"]\n",
    "\n",
    "\n",
    "table_str = \"\\\\begin{tabularx}{\\\\textwidth}{|c|\"\n",
    "\n",
    "for i in range(len(T_print)):\n",
    "    table_str = table_str + \">{\\centering\\\\arraybackslash}X|\"\n",
    "table_str = table_str+ \"}\\n\\hline\\n\"\n",
    "\n",
    "# Column names\n",
    "for T_i in T_print:\n",
    "    table_str += f\"&KLD $c = {round(1 / T_i,5)}\\downarrow$\"\n",
    "table_str += \"\\\\\\\\\\n\\hline\\n\"\n",
    "\n",
    "for k in base_paths_dict.keys():\n",
    "\n",
    "    if k in rows_to_highlight:\n",
    "        table_str += \"\\\\rowcolor{\" + highlight_color + \"}\"\n",
    "\n",
    "    table_str += f\"{row_name_dict[k]}\"\n",
    "\n",
    "    for T_i in T_print:\n",
    "\n",
    "        magnitude = np.floor(np.log10(abs( error_val_KLD_dicts[f\"{T_i}\"][k]))) \n",
    "        magnitude = abs(int(magnitude - 2))\n",
    "\n",
    "        if is_best_dict[f'{T_i}'][k]:\n",
    "            table_str += \"&\\\\textbf{\"+ f\"{round(val_KLD_dicts[f'{T_i}'][k],magnitude)}$\\pm${round(error_val_KLD_dicts[f'{T_i}'][k],magnitude)}\"+\"}\"\n",
    "        else:\n",
    "            table_str += f\"&{round(val_KLD_dicts[f'{T_i}'][k],magnitude)}$\\pm${round(error_val_KLD_dicts[f'{T_i}'][k],magnitude)}\"\n",
    "\n",
    "    table_str += \"\\\\\\\\\\n\"\n",
    "table_str += \"\\hline\\n\"\n",
    "\n",
    "table_str = table_str +\"\\end{tabularx}\"\n",
    "print(table_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization of the failre cases of different base line models\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = \"jet\"\n",
    "lim_list_grid = [[-9,9],[-9,9]]\n",
    "res_list_grid = [500,500]\n",
    "fs = 35\n",
    "T_list_plotting = [0.20691,0.54556,1.0,1.83298,4.83293]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INN_dict_last_cp = {}\n",
    "\n",
    "for key in base_paths_dict:\n",
    "\n",
    "    INN_last_i,_ = load_INN(base_path = base_paths_dict[key],use_last = False)\n",
    "\n",
    "    INN_dict_last_cp[key] = INN_last_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(len(base_paths_dict.keys())+1,len(T_list_plotting),figsize = (len(T_list_plotting) * 5,(1 +len(base_paths_dict.keys())) * 5))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i,T_i in enumerate(T_list_plotting):\n",
    "\n",
    "        # Ground truth distribution\n",
    "        p = partial(p_beta,gmm = gmm,beta = 1 / T_i, Z = Z_T_dict[f\"{T_i}\"])\n",
    "\n",
    "        pdf_grid,x_grid,y_grid = eval_pdf_on_grid_2D(\n",
    "            pdf=p,\n",
    "            x_lims = lim_list_grid[0],\n",
    "            y_lims = lim_list_grid[1],\n",
    "            x_res = res_list_grid[0],\n",
    "            y_res = res_list_grid[1],\n",
    "            device = device\n",
    "        )\n",
    "\n",
    "        grid_dict_i = {\"gt\":pdf_grid.detach().cpu()}\n",
    "        min_val = pdf_grid.min()\n",
    "        max_val = pdf_grid.max()\n",
    "\n",
    "        for k in base_paths_dict:\n",
    "\n",
    "            p_k = partial(INN_dict_last_cp[k].log_prob,beta_tensor = 1 / T_i)\n",
    "            pdf_grid_k,x_grid,y_grid = eval_pdf_on_grid_2D(\n",
    "                pdf=p_k,\n",
    "                x_lims = lim_list_grid[0],\n",
    "                y_lims = lim_list_grid[1],\n",
    "                x_res = res_list_grid[0],\n",
    "                y_res = res_list_grid[1],\n",
    "                device = device\n",
    "            )\n",
    "\n",
    "            pdf_grid_k = pdf_grid_k.detach().cpu().exp()\n",
    "\n",
    "            grid_dict_i[k] = pdf_grid_k\n",
    "\n",
    "            if min_val > pdf_grid_k.min():\n",
    "                min_val = pdf_grid_k.min()\n",
    "\n",
    "            if max_val < pdf_grid_k.max():\n",
    "                max_val = pdf_grid_k.max()\n",
    "\n",
    "        axes[0][i].set_title(f\"c = {round(1 / T_i,4)}\",fontsize = fs)\n",
    "        for j,k in enumerate(grid_dict_i.keys()):\n",
    "\n",
    "            axes[j][i].imshow(\n",
    "                grid_dict_i[k],\n",
    "                extent = [x_grid.detach().cpu().min(),\n",
    "                x_grid.detach().cpu().max(),\n",
    "                y_grid.detach().cpu().min(),\n",
    "                y_grid.detach().cpu().max()],\n",
    "                origin = 'lower',\n",
    "                cmap = cmap\n",
    "                )\n",
    "\n",
    "            axes[j][i].set(yticklabels=[])  # remove the tick labels\n",
    "            axes[j][i].tick_params(left=False)\n",
    "\n",
    "            axes[j][i].set(xticklabels=[])  # remove the tick labels\n",
    "            axes[j][i].tick_params(bottom=False)\n",
    "\n",
    "            if i == 0:\n",
    "                axes[j][0].set_ylabel(row_name_dict[k],fontsize = fs)\n",
    "\n",
    "            # Label\n",
    "            axes[j][i].text(-8.5,7.0, f\"{chr(ord('A') + j)}{i+1}\", fontsize = fs,c = \"w\")\n",
    "\n",
    "            plt.tight_layout()\n",
    "\n",
    "    plt.savefig(\"densities_2D_GMM_baselines_vs_TRADE.pdf\")\n",
    "    plt.close(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pinf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
