{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook is based on the exoeriemnt presented in the file volume-preserving-experiment.ipynb\n",
    "# Of the repository https://github.com/vislearn/Coupling-Universality\n",
    "# Authored by F.Draxler and S.Wahl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch \n",
    "from torch import Tensor\n",
    "import torch.distributions as D\n",
    "from FrEIA.utils import force_to\n",
    "from functools import partial\n",
    "import torch.nn as nn\n",
    "import FrEIA.modules as Fm\n",
    "import FrEIA.framework as Ff\n",
    "from typing import Iterable, Tuple, Callable,Any\n",
    "from FrEIA.modules.base import ShapeList\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import os\n",
    "\n",
    "from pinf.models.GMM import GMM\n",
    "from pinf.plot.utils import eval_pdf_on_grid_2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Settings\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(47)\n",
    "device = \"cpu\"\n",
    "n_layers = 15\n",
    "res = 500\n",
    "lim = 1.25\n",
    "lim_zoom_in = 0.25\n",
    "lr= 1e-3\n",
    "batch_size = 128\n",
    "milestones = [5000,10000,15000]\n",
    "gamma = 0.1\n",
    "n_batches = 25000\n",
    "save_freq = 5000\n",
    "train_new = False\n",
    "\n",
    "folder = \"../../results/visualization_2D_GMM_vp/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model definition\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modified GIN coupling block to allow variable jacobian determinant\n",
    "class ModifiedGINCouplingBlock(Fm.GINCouplingBlock):\n",
    "    def __init__(self, dims_in, dims_c=[], subnet_constructor: Callable[..., Any] = None, clamp: float = 2, clamp_activation: str | Callable[..., Any] = \"ATAN\", split_len: float | int = 0.5,normalize:bool = True):\n",
    "        '''\n",
    "        Additional parameters:\n",
    "            normalize:      Return constant Jacobian determinant if true\n",
    "        '''\n",
    "\n",
    "        super().__init__(dims_in, dims_c, subnet_constructor, clamp, clamp_activation, split_len)\n",
    "        self.normalize = normalize\n",
    "\n",
    "    def _coupling1(self, x1, u2, rev=False):\n",
    "\n",
    "        # notation (same for _coupling2):\n",
    "        # x: inputs (i.e. 'x-side' when rev is False, 'z-side' when rev is True)\n",
    "        # y: outputs (same scheme)\n",
    "        # *_c: variables with condition appended\n",
    "        # *1, *2: left half, right half\n",
    "        # a: all affine coefficients\n",
    "        # s, t: multiplicative and additive coefficients\n",
    "        # j: log det Jacobian\n",
    "\n",
    "        a2 = self.subnet2(u2)\n",
    "        s2, t2 = a2[:, :self.split_len1], a2[:, self.split_len1:]\n",
    "        s2 = self.clamp * self.f_clamp(s2)\n",
    "\n",
    "        #Constant Jacobian determinant of one\n",
    "        if self.normalize: \n",
    "            s2 = s2 - s2.mean(1, keepdim=True)\n",
    "            jac = 0.0\n",
    "\n",
    "        #Variable Jacobian determinant\n",
    "        else:\n",
    "            jac = s2.sum(-1)\n",
    "\n",
    "        if rev:\n",
    "            y1 = (x1 - t2) * torch.exp(-s2)\n",
    "            return y1, jac\n",
    "        else:\n",
    "            y1 = torch.exp(s2) * x1 + t2\n",
    "            return y1, jac\n",
    "        \n",
    "    def _coupling2(self, x2, u1, rev=False):\n",
    "        a1 = self.subnet1(u1)\n",
    "        s1, t1 = a1[:, :self.split_len2], a1[:, self.split_len2:]\n",
    "        s1 = self.clamp * self.f_clamp(s1)\n",
    "\n",
    "        #Constant Jacobian determinant of one\n",
    "        if self.normalize: \n",
    "            s1 = s1- s1.mean(1, keepdim=True)\n",
    "            jac = 0.0\n",
    "\n",
    "        #Variable Jacobian determinant\n",
    "        else:\n",
    "            jac = s1.sum(-1)\n",
    "\n",
    "        if rev:\n",
    "            y2 = (x2 - t1) * torch.exp(-s1)\n",
    "            return y2, -jac\n",
    "        else:\n",
    "            y2 = torch.exp(s1) * x2 + t1\n",
    "            return y2, jac\n",
    "        \n",
    "#Global scaling block for INN with constant Jacobian determinant\n",
    "class ScalingBlock(Fm.InvertibleModule):\n",
    "    def __init__(self, dims_in: ShapeList, dims_c: ShapeList = None):\n",
    "        super().__init__(dims_in, dims_c)\n",
    "\n",
    "        #Learnable scaling parameter\n",
    "        self.a = nn.Parameter(torch.ones([1]))\n",
    "\n",
    "    def output_dims(self, input_dims: ShapeList) -> ShapeList:\n",
    "        return input_dims\n",
    "    \n",
    "    def forward(self, x_or_z: Iterable[Tensor], c: Iterable[Tensor] = None, rev: bool = False, jac: bool = True) -> Tuple[Tuple[Tensor], Tensor]:\n",
    "        \n",
    "        x = x_or_z[0]\n",
    "        N= x.shape[0]\n",
    "        d = x.shape[1]\n",
    "\n",
    "        if rev:\n",
    "            jac = - d * torch.log(self.a)\n",
    "            x = x / self.a\n",
    "\n",
    "        else:\n",
    "            jac = + d * torch.log(self.a)\n",
    "            x = x * self.a\n",
    "\n",
    "        return ((x,),jac)     \n",
    "\n",
    "#Construct the subnetworks for the normalizing flows\n",
    "def get_subnet(c_in,c_out):\n",
    "\n",
    "    d_hidden = 128\n",
    "    layers = nn.Sequential(\n",
    "        nn.Linear(c_in,d_hidden),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(d_hidden,d_hidden),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(d_hidden,d_hidden),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(d_hidden,c_out)\n",
    "    )\n",
    "\n",
    "    #Initialize the weights of the linear layers\n",
    "    for layer in layers:\n",
    "        if isinstance(layer,nn.Linear):\n",
    "            nn.init.xavier_normal_(layer.weight)\n",
    "\n",
    "    #Set the weights and the bias of the final layer to zero\n",
    "    layers[-1].weight.data.fill_(0.0)\n",
    "    layers[-1].bias.data.fill_(0.0)\n",
    "\n",
    "    return layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the data distribution\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = torch.tensor([-0.5,-0.5]).reshape(1,-1)\n",
    "m2 = torch.tensor([0.5,0.5]).reshape(1,-1)\n",
    "means = torch.cat((m1,m2),0)\n",
    "\n",
    "S1 = (torch.eye(2) * 0.2).reshape(1,2,2)\n",
    "S2= (torch.eye(2) * 0.1).reshape(1,2,2)\n",
    "S = torch.cat((S1,S2),0)\n",
    "p_GMM = GMM(means = means,covs=S,weights = torch.tensor([0.5,0.5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the normalizing flow with constant Jacobian determinant\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INN_const_jac = Ff.SequenceINN(2)\n",
    "\n",
    "for i in range(n_layers):\n",
    "    INN_const_jac.append(module_class = ModifiedGINCouplingBlock,subnet_constructor = get_subnet,normalize = True)\n",
    "INN_const_jac.append(ScalingBlock)\n",
    "\n",
    "INN_const_jac.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training of an INN\n",
    "def train(INN,p_data:Callable,device:str,lr:float,milestones:list,gamma:float,batch_size:int,n_batches:int,experiment_name:str,save_freq:int):\n",
    "    \"\"\"\n",
    "    parameters:\n",
    "        INN:                Normalizing flow to train\n",
    "        p_data:             Function to get samples following the target distribution\n",
    "        lr:                 Learning rate\n",
    "        milestones:         Milestones for learning rate decay\n",
    "        gamma:              Factor for learning rate decay\n",
    "        batch_size:         Bacth size\n",
    "        n_batches:          Number of batches\n",
    "        experiment_name:    Name of the training run\n",
    "        save_freq:          Frequency of saving the state dict\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    INN.train()\n",
    "\n",
    "    #Create a folder for the training results\n",
    "    if not os.path.exists(os.path.join(folder,experiment_name)):\n",
    "        os.makedirs(os.path.join(folder,experiment_name))\n",
    "\n",
    "    #Latent distribution of the model\n",
    "    p_0 = force_to(D.MultivariateNormal(torch.zeros(2),torch.eye(2)),device)\n",
    "    \n",
    "    #Initialize the optimizer and the lr scheduler\n",
    "    optimizer = torch.optim.Adam(INN.parameters(),lr = lr)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer=optimizer,milestones=milestones,gamma =gamma)\n",
    "\n",
    "    #Storage\n",
    "    loss_storage = torch.zeros(n_batches)\n",
    "    jacobian_storage = torch.zeros([n_batches,2])\n",
    "\n",
    "    #Train the model\n",
    "    for i in tqdm.tqdm(range(n_batches)):\n",
    "        \n",
    "        #Get training data\n",
    "        x = p_data.sample(N = batch_size).to(device)\n",
    "\n",
    "        #Compute the objective\n",
    "        z,jac = INN(x)\n",
    "        nll = - (p_0.log_prob(z) + jac).mean()\n",
    "\n",
    "        #Optimize\n",
    "        optimizer.zero_grad()\n",
    "        nll.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        #Store the results\n",
    "        loss_storage[i] = nll.item()\n",
    "        jacobian_storage[i][0] = jac.mean()\n",
    "        jacobian_storage[i][1] = jac.std().item()\n",
    "\n",
    "        #Store the model\n",
    "        if ((i+1) % save_freq) == 0:\n",
    "            torch.save(INN.state_dict(),folder + f\"{experiment_name}/state-dict_iteration-{i+1}.pt\")\n",
    "\n",
    "    \n",
    "    #Save the recorded data\n",
    "    np.savetxt(folder +f\"{experiment_name}/loss.txt\",loss_storage.cpu().detach().numpy())\n",
    "    np.savetxt(folder +f\"{experiment_name}/jac.txt\",jacobian_storage.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_new:    \n",
    "    train(\n",
    "        p_data = p_GMM,\n",
    "        INN = INN_const_jac,\n",
    "        device = device,\n",
    "        lr = lr,\n",
    "        milestones = milestones,\n",
    "        gamma = gamma,\n",
    "        batch_size = batch_size,\n",
    "        n_batches = n_batches,\n",
    "        experiment_name =  \"const_jac_GMM_run-0\",\n",
    "        save_freq = save_freq\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the normalizing flow with variable Jacobian determinant\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INN_variable_jac = Ff.SequenceINN(2)\n",
    "\n",
    "for i in range(n_layers):\n",
    "    INN_variable_jac.append(module_class = ModifiedGINCouplingBlock,subnet_constructor = get_subnet,normalize = False)\n",
    "  \n",
    "INN_variable_jac.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_new:\n",
    "    train(\n",
    "        p_data = p_GMM,\n",
    "        INN = INN_variable_jac,\n",
    "        device = device,\n",
    "        lr = lr,\n",
    "        milestones = milestones,\n",
    "        gamma = gamma,\n",
    "        batch_size = batch_size,\n",
    "        n_batches = n_batches,\n",
    "        experiment_name =  \"variable_jac_GMM_run-0\",\n",
    "        save_freq = save_freq\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the trained models\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INN_const_jac.load_state_dict(torch.load(os.path.join(folder,f\"const_jac_GMM_run-0/state-dict_iteration-{n_batches}.pt\")))\n",
    "INN_const_jac.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INN_variable_jac.load_state_dict(torch.load(os.path.join(folder,f\"variable_jac_GMM_run-0/state-dict_iteration-{n_batches}.pt\")))\n",
    "INN_variable_jac.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the volume change of the different models\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Number of cells per dimension\n",
    "n_cells = 10\n",
    "n_res_cell = 200\n",
    "limLatent = 3\n",
    "\n",
    "#Get the area of a cell in the data space \n",
    "def get_transformed_Area(z_1_lims,z_2_lims,INN,res):\n",
    "\n",
    "    z_1_grid_ = torch.linspace(z_1_lims[0],z_1_lims[1],res)\n",
    "    z_2_grid_ = torch.linspace(z_2_lims[0],z_2_lims[1],res)\n",
    "\n",
    "    z_1_grid,z_2_grid = torch.meshgrid(z_1_grid_,z_2_grid_)\n",
    "\n",
    "    z_1_A = z_1_grid[1:,:-1]\n",
    "    z_2_A = z_2_grid[1:,:-1]\n",
    "                    \n",
    "    z_1_B = z_1_grid[1:,1:]\n",
    "    z_2_B = z_2_grid[1:,1:]\n",
    "\n",
    "    z_1_C = z_1_grid[:-1,1:]\n",
    "    z_2_C = z_2_grid[:-1,1:]\n",
    "\n",
    "    z_1_D = z_1_grid[:-1,:-1]\n",
    "    z_2_D = z_2_grid[:-1,:-1]\n",
    "\n",
    "    z_A = torch.cat((z_1_A.reshape(-1,1),z_2_A.reshape(-1,1)),1)\n",
    "    z_B = torch.cat((z_1_B.reshape(-1,1),z_2_B.reshape(-1,1)),1)\n",
    "    z_C = torch.cat((z_1_C.reshape(-1,1),z_2_C.reshape(-1,1)),1)\n",
    "    z_D = torch.cat((z_1_D.reshape(-1,1),z_2_D.reshape(-1,1)),1)\n",
    "\n",
    "    #Get the latent area\n",
    "    A_latent = 0.5 * ((z_1_A - z_1_C) * (z_2_B - z_2_D) + (z_2_A - z_2_C) * (z_1_D - z_1_B)).reshape(-1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        x_A = INN(z_A,rev=True)[0].detach().cpu()\n",
    "        x_B = INN(z_B,rev=True)[0].detach().cpu()\n",
    "        x_C = INN(z_C,rev=True)[0].detach().cpu()\n",
    "        x_D = INN(z_D,rev=True)[0].detach().cpu()\n",
    "\n",
    "    A_data  = 0.5 * ((x_A[:,0] - x_C[:,0]) * (x_B[:,1] - x_D[:,1]) + (x_D[:,0] - x_B[:,0]) * (x_A[:,1] - x_C[:,1])).abs() \n",
    "\n",
    "    #Get the centre of the polygons in the data space\n",
    "    x_centre = 0.25 * (x_A + x_B + x_C + x_D)\n",
    "\n",
    "    #Check if the polygon is convex\n",
    "    def cross_product(a, b, c):\n",
    "        \"\"\"\n",
    "        Berechnet das Kreuzprodukt der Vektoren AB und AC.\n",
    "        \"\"\"\n",
    "        ab = a-b  # Vektor AB\n",
    "        ac = a-c  # Vektor AC\n",
    "        return ab[:,0] * ac[:,1] - ab[:,1] * ac[:,0]\n",
    "\n",
    "    s1 = cross_product(x_A,x_B,x_D)\n",
    "    s2 = cross_product(x_B,x_C,x_A)\n",
    "    s3 = cross_product(x_C,x_D,x_B)\n",
    "    s4 = cross_product(x_D,x_A,x_C)\n",
    "\n",
    "    mask = (s2.sign() == s1.sign()) & (s3.sign() == s1.sign()) & (s4.sign() == s1.sign())\n",
    "\n",
    "    if mask.sum() != len(mask):\n",
    "        print(mask.sum())\n",
    "\n",
    "\n",
    "    return A_data[mask],A_latent[mask],x_centre[mask]\n",
    "\n",
    "#Get the position of the grid lines in the latent space\n",
    "z_1_latent_grid_pos = torch.linspace(-limLatent,limLatent,n_cells+1)\n",
    "z_2_latent_grid_pos = torch.linspace(-limLatent,limLatent,n_cells+1)\n",
    "\n",
    "A_data_list_const_jac = []\n",
    "A_data_list_var_jac = []\n",
    "\n",
    "x_centre_const_jac_list = []\n",
    "x_centre_var_jac_list = []\n",
    "\n",
    "for i in range(n_cells):\n",
    "    A_data_list_const_jac.append([])\n",
    "    A_data_list_var_jac.append([])\n",
    "\n",
    "    x_centre_const_jac_list.append([])\n",
    "    x_centre_var_jac_list.append([])\n",
    "\n",
    "    for j in range(n_cells):\n",
    "\n",
    "        A_data_const_jac,A_latent_const_jac,x_centre_const_jac = get_transformed_Area(\n",
    "            z_1_lims=[z_1_latent_grid_pos[i],z_1_latent_grid_pos[i+1]],\n",
    "            z_2_lims=[z_2_latent_grid_pos[j],z_2_latent_grid_pos[j+1]],\n",
    "            INN=INN_const_jac,\n",
    "            res=n_res_cell\n",
    "            )\n",
    "        \n",
    "        A_data_var_jac,A_latent_var_jac,x_centre_var_jac = get_transformed_Area(\n",
    "            z_1_lims=[z_1_latent_grid_pos[i],z_1_latent_grid_pos[i+1]],\n",
    "            z_2_lims=[z_2_latent_grid_pos[j],z_2_latent_grid_pos[j+1]],\n",
    "            INN=INN_variable_jac,\n",
    "            res=n_res_cell\n",
    "            )\n",
    "        \n",
    "        A_data_const_jac_ij = (A_data_const_jac / A_latent_const_jac).mean()\n",
    "        A_data_var_jac_ij = (A_data_var_jac / A_latent_var_jac).mean()\n",
    "\n",
    "        print(f\"Area for cell {i},{j} with constant jacobian: {A_data_const_jac_ij}\")\n",
    "        print(f\"Area for cell {i},{j} with variable jacobian: {A_data_var_jac_ij}\")\n",
    "\n",
    "        print(\"\")\n",
    "        \n",
    "\n",
    "        A_data_list_const_jac[i].append(A_data_const_jac_ij)\n",
    "        A_data_list_var_jac[i].append(A_data_var_jac_ij)\n",
    "\n",
    "        x_centre_const_jac_list[i].append(x_centre_const_jac)\n",
    "        x_centre_var_jac_list[i].append(x_centre_var_jac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_grid_lines = 1000\n",
    "\n",
    "z_points_grid_lines = torch.zeros([0,2])\n",
    "\n",
    "#Vertical lines\n",
    "for i,z_1_i in enumerate(z_1_latent_grid_pos):\n",
    "\n",
    "    z_1_grid = torch.ones(res_grid_lines).reshape(-1,1) * z_1_i\n",
    "    z_2_grid = torch.linspace(-limLatent,limLatent,res_grid_lines).reshape(-1,1)\n",
    "\n",
    "    points = torch.concatenate((z_1_grid,z_2_grid),dim=1)\n",
    "\n",
    "    z_points_grid_lines = torch.cat((z_points_grid_lines,points),dim=0)\n",
    "\n",
    "#Horizontal lines\n",
    "for i,z_2_i in enumerate(z_2_latent_grid_pos):\n",
    "\n",
    "    z_2_grid = torch.ones(res_grid_lines).reshape(-1,1) * z_2_i\n",
    "    z_1_grid = torch.linspace(-limLatent,limLatent,res_grid_lines).reshape(-1,1)\n",
    "\n",
    "    points = torch.concatenate((z_1_grid,z_2_grid),dim=1)\n",
    "\n",
    "    z_points_grid_lines = torch.cat((z_points_grid_lines,points),dim=0)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "#Get the grid lines in data space\n",
    "    x_points_grid_lines_const_jac,_ = INN_const_jac(z_points_grid_lines.to(device),rev = True)\n",
    "    x_points_grid_lines_variable_jac,_ = INN_variable_jac(z_points_grid_lines.to(device),rev = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluate the density on a grid\n",
    "\n",
    "#Latent distribution\n",
    "p_0 = force_to(D.MultivariateNormal(torch.zeros(2),torch.eye(2)),device)\n",
    "\n",
    "def eval_INN_dist(x,INN,device):\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        #Get the latent representation\n",
    "        z,jac = INN(x.to(device))\n",
    "\n",
    "        #Get log prob\n",
    "        log_prob = p_0.log_prob(z) + jac\n",
    "\n",
    "        return log_prob.exp()\n",
    "    \n",
    "\n",
    "p_const_jac = partial(eval_INN_dist,INN = INN_const_jac,device = device)\n",
    "p_variable_jac = partial(eval_INN_dist,INN = INN_variable_jac,device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_const_jac_grid,x_grid,y_grid = eval_pdf_on_grid_2D(pdf = p_const_jac,x_lims = [-lim,lim],y_lims = [-lim,lim],x_res = res,y_res = res)\n",
    "pdf_variable_jac_grid,x_grid,y_grid = eval_pdf_on_grid_2D(pdf = p_variable_jac,x_lims = [-lim,lim],y_lims = [-lim,lim],x_res = res,y_res = res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import Normalize\n",
    "\n",
    "fig,axes = plt.subplots(1,2,figsize=(12,4))\n",
    "\n",
    "A_data_var_jac = torch.tensor(A_data_list_var_jac)\n",
    "A_data_const_jac = torch.tensor(A_data_list_const_jac)\n",
    "\n",
    "norm = Normalize(vmin=min(A_data_var_jac.min().item(),A_data_const_jac.min().item()), vmax = max(A_data_var_jac.max().item(),A_data_const_jac.max().item()))\n",
    "\n",
    "cmap = \"viridis\"\n",
    "\n",
    "for i in range(n_cells):\n",
    "    for j in range(n_cells):\n",
    "\n",
    "        stp = 5\n",
    "\n",
    "        s = axes[0].scatter(\n",
    "            x_centre_const_jac_list[i][j].cpu().numpy()[:,0][::stp],\n",
    "            x_centre_const_jac_list[i][j].cpu().numpy()[:,1][::stp],\n",
    "            c = A_data_const_jac[i,j]* torch.ones(len(x_centre_const_jac_list[i][j][::stp])),\n",
    "            cmap=cmap,\n",
    "            s=1,\n",
    "            norm=norm\n",
    "            )\n",
    "        \n",
    "        s = axes[1].scatter(\n",
    "            x_centre_var_jac_list[i][j].cpu().numpy()[:,0][::stp],\n",
    "            x_centre_var_jac_list[i][j].cpu().numpy()[:,1][::stp],\n",
    "            c = A_data_var_jac[i,j]* torch.ones(len(x_centre_var_jac_list[i][j][::stp])),\n",
    "            cmap=cmap,\n",
    "            s=1,\n",
    "            norm=norm\n",
    "            )\n",
    "    \n",
    "\n",
    "#Plot the lines\n",
    "axes[0].scatter(x_points_grid_lines_const_jac[:,0],x_points_grid_lines_const_jac[:,1],s=0.5,c =\"k\")\n",
    "axes[1].scatter(x_points_grid_lines_variable_jac[:,0],x_points_grid_lines_variable_jac[:,1],s=0.5,c =\"k\")\n",
    "\n",
    "#Plot the contour lines of the dnesity\n",
    "n_levels = 5\n",
    "\n",
    "axes[0].contour(x_grid,y_grid,pdf_const_jac_grid,levels = n_levels,linewidths = 1.5,colors = \"w\",linestyles = \"dashed\")\n",
    "axes[1].contour(x_grid,y_grid,pdf_variable_jac_grid,levels = n_levels,linewidths = 1.5,colors = \"w\",linestyles = \"dashed\")\n",
    "\n",
    "axes[0].set_title(\"volume-preserving \")\n",
    "axes[1].set_title(\"non volume-preserving \")\n",
    "\n",
    "for i in range(2):\n",
    "    axes[i].spines['top'].set_visible(False)\n",
    "    axes[i].spines['right'].set_visible(False)\n",
    "    axes[i].spines['bottom'].set_visible(True)\n",
    "    axes[i].spines['left'].set_visible(True)\n",
    "\n",
    "    axes[i].set_xlabel(\"x\")\n",
    "    axes[i].set_ylabel(\"y\")\n",
    "\n",
    "    plt.colorbar(s,ax=axes[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\n",
    "    os.path.join(folder,\"GMM_volume_preservation.jpeg\"),\n",
    "    dpi = 300\n",
    "    )\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the optimal volume preserving flow:\n",
    "\n",
    "---\n",
    "\n",
    "construct the mapping with unit jacobian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limit\n",
    "lim = 3\n",
    "grid_res = 400\n",
    "\n",
    "# Get the latent distribution\n",
    "p_0 = force_to(D.MultivariateNormal(torch.zeros(2),torch.eye(2)),device)\n",
    "\n",
    "x_vals = torch.linspace(-lim,lim,grid_res)\n",
    "y_vals = torch.linspace(-lim,lim,grid_res)\n",
    "\n",
    "x_grid,y_grid = torch.meshgrid(x_vals,y_vals)\n",
    "\n",
    "points = torch.cat((x_grid.reshape(-1,1),y_grid.reshape(-1,1)),1)\n",
    "\n",
    "density_points_target = p_GMM.log_prob(points).exp()\n",
    "density_points_latent = p_0.log_prob(points).exp()\n",
    "\n",
    "def construct_data_unit_vol_change():\n",
    "    \"\"\"\n",
    "    For a given latent distribution compute the optimal data distribution for a unit volume change.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the sorting by the values of the target density\n",
    "    idx_data = density_points_target.argsort(descending = True)\n",
    "    points_sorted = points[idx_data]\n",
    "\n",
    "    # Get the sorting by the values of the latent density\n",
    "    idx_latent = density_points_latent.argsort(descending = True)\n",
    "    density_points_latent_sorted = density_points_latent[idx_latent]\n",
    "\n",
    "    # Arange the densty and the points on grids\n",
    "    sorted_indices = np.lexsort((points_sorted[:, 1], points_sorted[:, 0]))\n",
    "\n",
    "    points_sorted = points_sorted[sorted_indices]\n",
    "    density_points_latent_sorted = density_points_latent_sorted[sorted_indices]\n",
    "\n",
    "\n",
    "    x_grid = points_sorted[:,0].reshape(grid_res,grid_res)\n",
    "    y_grid = points_sorted[:,1].reshape(grid_res,grid_res)\n",
    "\n",
    "    density_points_latent_sorted = density_points_latent_sorted.reshape(grid_res,grid_res)\n",
    "\n",
    "    return x_grid,y_grid,density_points_latent_sorted\n",
    "\n",
    "def construct_latent_unit_vol_change():\n",
    "    \"\"\"\n",
    "    For a given latent distribution compute the optimal data distribution for a unit volume change.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the sorting by the values of the target density\n",
    "    idx_latent = density_points_latent.argsort(descending = True)\n",
    "    points_sorted = points[idx_latent]\n",
    "\n",
    "    # Get the sorting by the values of the latent density\n",
    "    idx_data = density_points_target.argsort(descending = True)\n",
    "    density_points_data_sorted = density_points_target[idx_data]\n",
    "\n",
    "    # Arange the densty and the points on grids\n",
    "    sorted_indices = np.lexsort((points_sorted[:, 1], points_sorted[:, 0]))\n",
    "\n",
    "    points_sorted = points_sorted[sorted_indices]\n",
    "    density_points_data_sorted = density_points_data_sorted[sorted_indices]\n",
    "\n",
    "\n",
    "    x_grid = points_sorted[:,0].reshape(grid_res,grid_res)\n",
    "    y_grid = points_sorted[:,1].reshape(grid_res,grid_res)\n",
    "\n",
    "    density_points_data_sorted = density_points_data_sorted.reshape(grid_res,grid_res)\n",
    "\n",
    "    return x_grid,y_grid,density_points_data_sorted\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_grid,y_grid,p_z_star = construct_latent_unit_vol_change()\n",
    "\n",
    "dA = (x_vals[1] - x_vals[0]) * (y_vals[1] - y_vals[0])\n",
    "\n",
    "#Approximate the covarianve matrix\n",
    "cov = torch.zeros(2,2)\n",
    "\n",
    "mean_x = (x_grid.reshape(-1) * p_z_star.reshape(-1) * dA).sum()\n",
    "mean_y = (y_grid.reshape(-1) * p_z_star.reshape(-1) * dA).sum()\n",
    "\n",
    "var_x = ((x_grid.reshape(-1) - mean_x)**2 * p_z_star.reshape(-1) * dA).sum()\n",
    "var_y = ((y_grid.reshape(-1) - mean_y)**2 * p_z_star.reshape(-1) * dA).sum()\n",
    "cov_xy = ((x_grid.reshape(-1) - mean_x) * (y_grid.reshape(-1) - mean_y) * p_z_star.reshape(-1) * dA).sum()\n",
    "\n",
    "cov[0,0] = var_x\n",
    "cov[1,1] = var_y\n",
    "cov[0,1] = cov_xy\n",
    "cov[1,0] = cov_xy\n",
    "\n",
    "# Get the determinant of the covariance matrix\n",
    "det_cov = cov[0,0] * cov[1,1] - cov[0,1] * cov[1,0]\n",
    "\n",
    "C = det_cov**(- 1 / 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_grid,y_grid,p_data_star_constructed = construct_data_unit_vol_change()\n",
    "\n",
    "p_x_star = p_data_star_constructed ** (C**2)\n",
    "Z_x_star = p_x_star.sum() * dA\n",
    "p_x_star = p_x_star / Z_x_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_const_jac = partial(eval_INN_dist,INN = INN_const_jac,device = device)\n",
    "p_variable_jac = partial(eval_INN_dist,INN = INN_variable_jac,device = device)\n",
    "\n",
    "densits_points_const_jac = p_const_jac(points).cpu()\n",
    "densits_points_variable_jac = p_variable_jac(points).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(2,2,figsize=(13,13))\n",
    "\n",
    "lim_x = 1.5\n",
    "cmap = \"jet\"\n",
    "s = 45\n",
    "fs = 20\n",
    "\n",
    "density_list = [\n",
    "    density_points_target.reshape(grid_res,grid_res),\n",
    "    p_x_star,\n",
    "    densits_points_variable_jac.reshape(grid_res,grid_res),\n",
    "    densits_points_const_jac.reshape(grid_res,grid_res),\n",
    "]\n",
    "\n",
    "d_min = None\n",
    "d_max = None\n",
    "\n",
    "for i in range(len(density_list)):\n",
    "    if (d_min is None) or (density_list[i].min() < d_min):\n",
    "        d_min = density_list[i].min()\n",
    "    if (d_max is None) or (density_list[i].max() > d_max):\n",
    "        d_max = density_list[i].max()\n",
    "\n",
    "print(d_min,d_max)\n",
    "\n",
    "titels = [\n",
    "    r\"$p^*(x,y)$\",\n",
    "    r\"$p_{\\text{optim}}^{\\text{vp}}(x,y)$\",\n",
    "    r\"$|f_{\\theta}'| \\neq const.$\",\n",
    "    r\"$|f_{\\theta}'| = const.$\"\n",
    "]\n",
    "    \n",
    "\n",
    "for i,ax in enumerate(axes.flatten()):\n",
    "    ax.pcolormesh(x_grid,y_grid,density_list[i],cmap=cmap,vmin=d_min,vmax=d_max)\n",
    "    ax.contour(x_grid,y_grid,density_list[i],levels = 5,linewidths = 1.5,colors = \"k\")\n",
    "    \n",
    "for i,ax in enumerate(axes.flatten()):\n",
    "    ax.set_xlim(-lim_x,lim_x)\n",
    "    ax.set_ylim(-lim_x,lim_x)\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_aspect(\"equal\")\n",
    "    ax.set_xlabel(\"x\",fontsize=fs)\n",
    "    ax.set_ylabel(\"y\",fontsize=fs)\n",
    "    ax.set_title(titels[i],fontsize=fs)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "plt.contour\n",
    "plt.savefig(os.path.join(folder,\"unit_volume_change.jpeg\"),dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pinf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
