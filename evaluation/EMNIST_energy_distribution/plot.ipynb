{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader\n",
    "import tqdm\n",
    "\n",
    "from pinf.datasets.datasets import get_EMNIST_datasets\n",
    "from pinf.models.construct_INN_EMNIST import set_up_sequence_INN_MNIST_like\n",
    "from pinf.models.histogram import HistogramDist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set parameters of the evaluation\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"EMNIST_digits\"\n",
    "\n",
    "if experiment_name == \"EMNIST_digits\":\n",
    "    model_folder = \"../../results/runs_EMNIST_digits/<Your experiment name>/lightning_logs/version_0/\"\n",
    "    data_dim = 28 * 28\n",
    "    n_samples_plot_per_class = 15\n",
    "    n_classes = 10\n",
    "\n",
    "else:\n",
    "    raise ValueError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the INN\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = yaml.safe_load(Path(model_folder + \"/hparams.yaml\").read_text())\n",
    "state_dict_folder = os.path.join(model_folder,\"checkpoints/\")\n",
    "state_dict_files = os.listdir(state_dict_folder)\n",
    "\n",
    "if len(state_dict_files) > 1:\n",
    "    raise ValueError(\"more than one state ditct provided\")\n",
    "\n",
    "state_dict_file = os.path.join(state_dict_folder,state_dict_files[0])\n",
    "print(state_dict_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Folder for results\n",
    "folder = f\"../../results/{experiment_name}/\"\n",
    "\n",
    "if not os.path.exists(folder):\n",
    "    os.makedirs(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    INN = set_up_sequence_INN_MNIST_like(config=config)\n",
    "    INN.load_state_dict(path = state_dict_file)\n",
    "    INN.train(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the validation data\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS_training,DS_validation = get_EMNIST_datasets(\n",
    "    data_folder = \"../../data/\",\n",
    "    mean_normalization = config[\"config_data\"][\"init_data_set_params\"][\"mean_normalization\"],\n",
    "    scale_normalization = config[\"config_data\"][\"init_data_set_params\"][\"scale_normalization\"],\n",
    "    sigma_dequantization = 0.0,\n",
    "    split = \"digits\"\n",
    ")\n",
    "\n",
    "val_DL = DataLoader(dataset=DS_validation,batch_size = 512)\n",
    "train_DL = DataLoader(dataset=DS_training,batch_size = 512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot states\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_states(samples_list:list,n_samples_per_class:int,n_classes:int,name:str=None,rotate:bool = False)->None:\n",
    "    fig,axes =  plt.subplots(n_classes,n_samples_per_class,figsize = (n_samples_per_class * 5,n_classes * 5))\n",
    "\n",
    "    for i in range(n_classes):\n",
    "        for j in range(n_samples_per_class):\n",
    "\n",
    "            if rotate:\n",
    "                im = samples_list[i][j].permute(1,0)\n",
    "            else:\n",
    "                im = samples_list[i][j]\n",
    "\n",
    "            axes[i][j].imshow(im,cmap = \"Grays\")\n",
    "            axes[i][j].axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if name is not None:\n",
    "        plt.savefig(\n",
    "        os.path.join(folder,name),\n",
    "        bbox_inches='tight'\n",
    "    )\n",
    "    plt.close(fig)\n",
    "\n",
    "n_samples_plot_per_class = 6 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get validation samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_list_validation = []\n",
    "\n",
    "for i in range(n_classes):\n",
    "    for batch in val_DL:\n",
    "        mask = (batch[1] == i)\n",
    "        \n",
    "        im_i = batch[0][mask][:n_samples_plot_per_class].squeeze().detach().cpu()\n",
    "\n",
    "        im_list_validation.append(im_i)\n",
    "\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_states(samples_list = im_list_validation,n_samples_per_class = n_samples_plot_per_class,n_classes = n_classes,rotate=True,name = \"val_samples.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(1,2,figsize = (20,10))            \n",
    "\n",
    "im_1 = im_list_validation[2][3].permute(1,0)\n",
    "im_2 = im_list_validation[2][1].permute(1,0)\n",
    "axes[0].imshow(im_1,cmap = \"Grays\")\n",
    "axes[0].axis(\"off\")\n",
    "\n",
    "axes[1].imshow(im_2,cmap = \"Grays\")\n",
    "axes[1].axis(\"off\")\n",
    "\n",
    "plt.savefig(os.path.join(folder,\"Different_types_letter_2.pdf\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(1,2,figsize = (20,10))            \n",
    "\n",
    "im_1 = im_list_validation[7][2].permute(1,0)\n",
    "im_2 = im_list_validation[7][3].permute(1,0)\n",
    "axes[0].imshow(im_1,cmap = \"Grays\")\n",
    "axes[0].axis(\"off\")\n",
    "\n",
    "axes[1].imshow(im_2,cmap = \"Grays\")\n",
    "axes[1].axis(\"off\")\n",
    "\n",
    "plt.savefig(os.path.join(folder,\"Different_types_letter_7.pdf\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get INN samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_tensor = torch.ones(n_classes,n_samples_plot_per_class,device = config[\"device\"])\n",
    "c_tensor *= torch.arange(n_classes,device = config[\"device\"]).reshape(-1,1)\n",
    "c_tensor = c_tensor.reshape(-1,1).long()\n",
    "\n",
    "x_INN = INN.sample(n_samples = len(c_tensor),beta_tensor = c_tensor).detach().cpu()\n",
    "\n",
    "im_list = []\n",
    "\n",
    "for i in range(n_classes):\n",
    "    im_list.append(x_INN[i * n_samples_plot_per_class:(i+1)*n_samples_plot_per_class].squeeze().detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_states(samples_list = im_list,n_samples_per_class = n_samples_plot_per_class,n_classes = n_classes,rotate=True,name = \"model_samples.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample energies following the learned distribution\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples_energy = int(1e6)\n",
    "bs_energy = int(1e3)\n",
    "\n",
    "n_batches = int(n_samples_energy / bs_energy)\n",
    "\n",
    "INN.eval()\n",
    "\n",
    "if not os.path.exists(folder):\n",
    "    os.makedirs(folder)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for c in tqdm.tqdm(range(n_classes)):\n",
    "\n",
    "        if os.path.exists(os.path.join(folder,f\"energies_INN_c_{c}.pt\")):\n",
    "            continue\n",
    "\n",
    "        energies_c = torch.zeros([0])\n",
    "\n",
    "        for i in tqdm.tqdm(range(n_batches)):\n",
    "            c_tensor = c * torch.ones(bs_energy,device = config[\"device\"]).reshape(-1,1) \n",
    "            x_i = INN.sample(n_samples=bs_energy,beta_tensor=c_tensor.long())\n",
    "\n",
    "            energies_ci = - INN.log_prob(x_i,c_tensor.long()).detach().cpu()\n",
    "\n",
    "            energies_c = torch.cat((energies_c,energies_ci),0)\n",
    "\n",
    "        # Save the recorded energies\n",
    "        torch.save(energies_c,os.path.join(folder,f\"energies_INN_c_{c}.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the energies of the validation set\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for c in tqdm.tqdm(range(n_classes)):\n",
    "\n",
    "        if os.path.exists(os.path.join(folder,f\"energies_data_c_{c}.pt\")):\n",
    "            continue\n",
    "\n",
    "        energies_c = torch.zeros([0])\n",
    "\n",
    "        for batch in val_DL:\n",
    "            mask = (batch[1] == c)\n",
    "        \n",
    "            x_i = batch[0][mask].to(config[\"device\"])\n",
    "\n",
    "            c_tensor = c * torch.ones(len(x_i),device = config[\"device\"]).reshape(-1,1) \n",
    "\n",
    "            energies_ci = - INN.log_prob(x_i,c_tensor.long()).detach().cpu()\n",
    "\n",
    "            energies_c = torch.cat((energies_c,energies_ci),0)\n",
    "\n",
    "        for batch in train_DL:\n",
    "            mask = (batch[1] == c)\n",
    "        \n",
    "            x_i = batch[0][mask].to(config[\"device\"])\n",
    "\n",
    "            c_tensor = c * torch.ones(len(x_i),device = config[\"device\"]).reshape(-1,1) \n",
    "\n",
    "            energies_ci = - INN.log_prob(x_i,c_tensor.long()).detach().cpu()\n",
    "\n",
    "            energies_c = torch.cat((energies_c,energies_ci),0)\n",
    "\n",
    "        # Save the recorded energies\n",
    "        torch.save(energies_c,os.path.join(folder,f\"energies_data_c_{c}.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the energies of the validation set with noise\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for c in tqdm.tqdm(range(n_classes)):\n",
    "\n",
    "        if os.path.exists(os.path.join(folder,f\"energies_data_noisy_c_{c}.pt\")):\n",
    "            continue\n",
    "\n",
    "        energies_c = torch.zeros([0])\n",
    "\n",
    "        for batch in val_DL:\n",
    "            mask = (batch[1] == c)\n",
    "        \n",
    "            x_i = batch[0][mask].to(config[\"device\"])\n",
    "            x_i += torch.randn_like(x_i) * config[\"config_data\"][\"data_set_config\"][\"sigma_dequantization\"]\n",
    "\n",
    "            c_tensor = c * torch.ones(len(x_i),device = config[\"device\"]).reshape(-1,1) \n",
    "\n",
    "            energies_ci = - INN.log_prob(x_i,c_tensor.long()).detach().cpu()\n",
    "\n",
    "            energies_c = torch.cat((energies_c,energies_ci),0)\n",
    "\n",
    "        for batch in train_DL:\n",
    "            mask = (batch[1] == c)\n",
    "        \n",
    "            x_i = batch[0][mask].to(config[\"device\"])\n",
    "            x_i += torch.randn_like(x_i) * config[\"config_data\"][\"data_set_config\"][\"sigma_dequantization\"]\n",
    "\n",
    "            c_tensor = c * torch.ones(len(x_i),device = config[\"device\"]).reshape(-1,1) \n",
    "\n",
    "            energies_ci = - INN.log_prob(x_i,c_tensor.long()).detach().cpu()\n",
    "\n",
    "            energies_c = torch.cat((energies_c,energies_ci),0)\n",
    "\n",
    "        # Save the recorded energies\n",
    "        torch.save(energies_c,os.path.join(folder,f\"energies_data_noisy_c_{c}.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the stored pseudo-energies and compute the empirical distribution\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_e_INN_list = []\n",
    "\n",
    "n_bins = 500\n",
    "\n",
    "min_e = -4000\n",
    "max_e = -2500\n",
    "\n",
    "for c in tqdm.tqdm(range(n_classes)):\n",
    "\n",
    "    \n",
    "    energies_c = torch.load(os.path.join(folder,f\"energies_INN_c_{c}.pt\"))\n",
    "    mask = torch.isfinite(energies_c)\n",
    "    energies_c = energies_c[mask]\n",
    "\n",
    "    mask = (energies_c >= min_e) * (energies_c <= max_e)\n",
    "    energies_c = energies_c[mask]\n",
    "\n",
    "    p_e_c = HistogramDist(\n",
    "        data = energies_c,\n",
    "        n_bins = n_bins\n",
    "    )\n",
    "\n",
    "    p_e_INN_list.append(p_e_c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_e_val_list = []\n",
    "\n",
    "for c in tqdm.tqdm(range(n_classes)):\n",
    "    energies_c = torch.load(os.path.join(folder,f\"energies_data_c_{c}.pt\"))\n",
    "\n",
    "    p_e_c = HistogramDist(\n",
    "        data = energies_c,\n",
    "        n_bins = n_bins\n",
    "    )\n",
    "\n",
    "    p_e_val_list.append(p_e_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_e_val_noisy_list = []\n",
    "\n",
    "for c in tqdm.tqdm(range(n_classes)):\n",
    "    energies_c = torch.load(os.path.join(folder,f\"energies_data_noisy_c_{c}.pt\"))\n",
    "\n",
    "    p_e_c = HistogramDist(\n",
    "        data = energies_c,\n",
    "        n_bins = n_bins\n",
    "    )\n",
    "\n",
    "    p_e_val_noisy_list.append(p_e_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the distributions of the pseudo-energies:\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(5,2,figsize = (13,12))\n",
    "\n",
    "fs = 15\n",
    "e_eval = torch.linspace(min_e-100,max_e+100,1000)\n",
    "\n",
    "for i,ax in enumerate(axes.flatten()):\n",
    "\n",
    "    ax.set_title(f\"class '{i}'\",fontsize = fs)\n",
    "    ax.plot(e_eval,p_e_INN_list[i](e_eval),c = \"k\",lw = 3,label = \"INN samples\")\n",
    "    ax.plot(e_eval,p_e_val_list[i](e_eval),c = \"orange\",lw = 3,label = \"observed samples\")\n",
    "    ax.plot(e_eval,p_e_val_noisy_list[i](e_eval),c = \"b\",lw = 3,label = \"observed samples + noise\")\n",
    "    ax.tick_params(axis='x', labelsize=fs)\n",
    "    ax.tick_params(axis='y', labelsize=fs)\n",
    "    ax.set_xlabel(r\"$e$\",fontsize = fs)\n",
    "    ax.set_ylabel(r\"$p(e)$\",fontsize = fs)\n",
    "\n",
    "\n",
    "handles, labels = [], []\n",
    "\n",
    "for handle, label in zip(*ax.get_legend_handles_labels()):\n",
    "        handles.append(handle)\n",
    "        labels.append(label)\n",
    "    \n",
    "fig.legend(handles, labels, loc='upper center', bbox_to_anchor=(0.5, -0.0), ncol=3,fontsize = fs)\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\n",
    "    os.path.join(folder,f\"energy_distributions.pdf\"),\n",
    "    bbox_inches='tight'\n",
    ")\n",
    "plt.close(fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pinf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
