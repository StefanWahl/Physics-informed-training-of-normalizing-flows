{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.cm import get_cmap\n",
    "import matplotlib as mplt\n",
    "import json\n",
    "from tbparse import SummaryReader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper to find the best run in a folder containing several runs\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_run(experiment_folder_list:list[str])->None:\n",
    "    \"\"\"\n",
    "    Find best performing training run:\n",
    "\n",
    "    parameters:\n",
    "        experiment_folder_list:     List of folders containing different collections of experiments\n",
    "    \"\"\"\n",
    "\n",
    "    best_mean_validation_KL = None\n",
    "\n",
    "    for experiment_folder in experiment_folder_list:\n",
    "\n",
    "        subfolders = os.listdir(experiment_folder)\n",
    "        \n",
    "        for subfolder in subfolders:\n",
    "\n",
    "            full_path = os.path.join(experiment_folder,subfolder)\n",
    "            \n",
    "            reader_k = SummaryReader(full_path,extra_columns=set([\"wall_time\"]))\n",
    "            df_k = reader_k.scalars\n",
    "            df_red = df_k[(df_k[\"tag\"] == \"model_performance/mean_validation_KL\")]\n",
    "            kl_k = df_red[\"value\"].values\n",
    "\n",
    "            if (best_mean_validation_KL is None) or (best_mean_validation_KL > kl_k.min()):\n",
    "                best_folder = full_path\n",
    "                best_mean_validation_KL = kl_k.min()\n",
    "\n",
    "            print(kl_k.min(),\"\\t\",full_path)\n",
    "\n",
    "    print(\"\\n\\nBest folder\")\n",
    "    print(best_folder)\n",
    "\n",
    "search_best = False\n",
    "\n",
    "if search_best:\n",
    "\n",
    "    folder_list = [\n",
    "        \"../../results/runs_ScalarTheory/<Your experiment name>/lightning_logs/\"\n",
    "        ]\n",
    "    find_best_run(folder_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the paths\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_MODE = \"SCALAR_THEORY_N16_TWO_BASE_PARAMETERS\"\n",
    "\n",
    "# Limits for plotting\n",
    "lim_susceptibility = {\n",
    "    \"SCALAR_THEORY_N8_TWO_BASE_PARAMETERS\":[-0.5,25],\n",
    "    \"SCALAR_THEORY_N16_TWO_BASE_PARAMETERS\":[-0.5,40],\n",
    "}\n",
    "\n",
    "lim_binder = {\n",
    "    \"SCALAR_THEORY_N8_TWO_BASE_PARAMETERS\":[-0.5,1],\n",
    "    \"SCALAR_THEORY_N16_TWO_BASE_PARAMETERS\":[-1,1],\n",
    "}\n",
    "\n",
    "if EXPERIMENT_MODE == \"SCALAR_THEORY_N8_TWO_BASE_PARAMETERS\":\n",
    "\n",
    "    model_to_eval = \"best\"\n",
    "    N = 8\n",
    "\n",
    "    path_dict = {\n",
    "        \"TRADE_no_grid\":    \"../../results/runs_ScalarTheory/<Your experiment name>/lightning_logs/version_0\",\n",
    "        \"TRADE_grid\":       \"../../results/runs_ScalarTheory/<Your experiment name>/lightning_logs/version_0\",\n",
    "        \"NLL_only\":         \"../../results/runs_ScalarTheory/<Your experiment name>/lightning_logs/version_0\",\n",
    "        \"reverse_KL\":       \"../../results/runs_ScalarTheory/<Your experiment name>/lightning_logs/version_0\",\n",
    "        \"reverse_KL_NLL\":   \"../../results/runs_ScalarTheory/<Your experiment name>/lightning_logs/version_0\"\n",
    "    }\n",
    "\n",
    "    folder_dict_random_seeds = {\n",
    "        \"TRADE_no_grid\":    \"../../results/runs_ScalarTheory/<Your experiment name>/lightning_logs/\",\n",
    "        \"TRADE_grid\":       \"../../results/runs_ScalarTheory/<Your experiment name>/lightning_logs/\",\n",
    "        \"reverse_KL_NLL\":   \"../../results/runs_ScalarTheory/<Your experiment name>/lightning_logs/\"\n",
    "    }\n",
    "\n",
    "elif EXPERIMENT_MODE == \"SCALAR_THEORY_N16_TWO_BASE_PARAMETERS\":\n",
    "    \n",
    "    model_to_eval = \"best\"\n",
    "    N = 16\n",
    "\n",
    "    path_dict = {\n",
    "        \"NLL_only\":         \"../../results/runs_ScalarTheory/<Your experiment name>/lightning_logs/version_0\",\n",
    "        \"reverse_KL\":       \"../../results/runs_ScalarTheory/<Your experiment name>/lightning_logs/version_0\",\n",
    "        \"reverse_KL_NLL\":   \"../../results/runs_ScalarTheory/<Your experiment name>/lightning_logs/version_0\",\n",
    "        \"TRADE_no_grid\":    \"../../results/runs_ScalarTheory/<Your experiment name>/lightning_logs/version_0\"\n",
    "    }\n",
    "\n",
    "figure_folder = f\"./Figures_{EXPERIMENT_MODE}/\"\n",
    "\n",
    "if not os.path.exists(figure_folder):\n",
    "    os.makedirs(figure_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_dict = {\n",
    "    \"TRADE_no_grid\":\"TRADE (no grid)\",\n",
    "    \"TRADE_grid\":\"TRADE (grid)\",\n",
    "    \"NLL_only\":\"NLL only\",\n",
    "    \"reverse_KL\":\"Reverse KLD\",\n",
    "    \"reverse_KL_NLL\":\"Reverse KLD + NLL\"\n",
    "}\n",
    "\n",
    "fs = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a table for the validation NLLs:\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_table_str_sub_table(\n",
    "        rows_value_dict,\n",
    "        rows_error_dict,\n",
    "        row_key_to_row_label_dict,\n",
    "        col_key_to_col_label_dict,\n",
    "        rows_to_highlight = [],\n",
    "        col_label_prefix = \"NLL \",\n",
    "        col_label_suffix = \"$\\downarrow$\",\n",
    "        highlight_color = \"lightgray\"):\n",
    "\n",
    "    table_str = \"\\\\begin{tabularx}{\\\\textwidth}{|c|\"\n",
    "\n",
    "    for i in range(len(col_key_to_col_label_dict.keys())):\n",
    "        table_str = table_str + \">{\\centering\\\\arraybackslash}X|\"\n",
    "    table_str = table_str+ \"}\\n\\hline\\n\"\n",
    "\n",
    "    # Column names\n",
    "    for col_key in col_key_to_col_label_dict.keys():\n",
    "        table_str += \"&\" + col_label_prefix + col_key_to_col_label_dict[col_key] + col_label_suffix\n",
    "    table_str += \"\\\\\\\\\\n\\hline\\n\"\n",
    "\n",
    "    # For each column get the best performing entry\n",
    "    is_best_dict = {}\n",
    "\n",
    "    for row_label in rows_value_dict.keys():\n",
    "        is_best_dict[row_label] = {}\n",
    "\n",
    "        for col_label in col_key_to_col_label_dict.keys():\n",
    "            is_best_dict[row_label][col_label] = False\n",
    "\n",
    "    for col_label in col_key_to_col_label_dict.keys():\n",
    "\n",
    "        best_row_i = None\n",
    "\n",
    "        for row_label in rows_value_dict.keys():\n",
    "\n",
    "            if (best_row_i is None) or (rows_value_dict[row_label][col_label] < best_row_val_i):\n",
    "                best_row_i = row_label\n",
    "                best_row_val_i = rows_value_dict[row_label][col_label]\n",
    "\n",
    "        is_best_dict[best_row_i][col_label] = True\n",
    "\n",
    "    # Fill rows\n",
    "    for row_label in rows_value_dict.keys():\n",
    "        \n",
    "        # Highlight rows\n",
    "        if row_label in rows_to_highlight:\n",
    "            table_str += \"\\\\rowcolor{\" + highlight_color + \"}\"\n",
    "\n",
    "        table_str += row_key_to_row_label_dict[row_label]\n",
    "        \n",
    "        for col_label in col_key_to_col_label_dict.keys():\n",
    "\n",
    "            # Round the entries of the cell\n",
    "            magnitude = np.floor(np.log10(abs(rows_error_dict[row_label][col_label]))) \n",
    "            magnitude = abs(int(magnitude - 2))\n",
    "\n",
    "            if is_best_dict[row_label][col_label]:\n",
    "                table_str += \"&\\\\textbf{\"+ f\"{round(rows_value_dict[row_label][col_label],magnitude)}$\\pm${round(rows_error_dict[row_label][col_label],magnitude)}\"+\"}\"\n",
    "            else:\n",
    "                table_str += f\"&{round(rows_value_dict[row_label][col_label],magnitude)}$\\pm${round(rows_error_dict[row_label][col_label],magnitude)}\"\n",
    "\n",
    "        table_str += \"\\\\\\\\\\n\"\n",
    "\n",
    "    table_str += \"\\hline\\n\"\n",
    "\n",
    "    table_str = table_str +\"\\end{tabularx}\"\n",
    "\n",
    "    return table_str\n",
    "\n",
    "def get_table_str(\n",
    "        rows_value_dict,\n",
    "        rows_error_dict,\n",
    "        row_key_to_row_label_dict,\n",
    "        col_key_to_col_label_dict,\n",
    "        rows_to_highlight = [],\n",
    "        col_label_prefix = \"NLL \",\n",
    "        col_label_suffix = \"$\\downarrow$\",\n",
    "        highlight_color = \"lightgray\",\n",
    "        values_per_row = 3):\n",
    "    \n",
    "    table_str = \"\"\n",
    "\n",
    "    \n",
    "    for i in range(0,len(col_key_to_col_label_dict.keys()),values_per_row):\n",
    "\n",
    "        sub_table_column_names = list(col_key_to_col_label_dict.keys())[i:min(i + values_per_row,len(col_key_to_col_label_dict.keys()))]\n",
    "        \n",
    "        table_str += f\"%Subtable {int(i / values_per_row) + 1}\\n\"\n",
    "\n",
    "        sub_table_row_value_dict = {}\n",
    "        sub_table_row_error_dict = {}\n",
    "        sub_table_col_key_to_col_label_dict = {}\n",
    "\n",
    "        for row_label in rows_value_dict.keys():\n",
    "\n",
    "            sub_table_row_value_dict[row_label] = {}\n",
    "            sub_table_row_error_dict[row_label] = {}\n",
    "\n",
    "            for col_label in col_key_to_col_label_dict.keys():\n",
    "                \n",
    "                if col_label in sub_table_column_names:\n",
    "                    sub_table_row_value_dict[row_label][col_label] = rows_value_dict.get(row_label).get(col_label)\n",
    "                    sub_table_row_error_dict[row_label][col_label] = rows_error_dict.get(row_label).get(col_label)\n",
    "                    sub_table_col_key_to_col_label_dict[col_label] = col_key_to_col_label_dict.get(col_label)\n",
    "\n",
    "        sub_table_str = get_table_str_sub_table(\n",
    "            rows_value_dict = sub_table_row_value_dict,\n",
    "            rows_error_dict = sub_table_row_error_dict,\n",
    "            row_key_to_row_label_dict = row_key_to_row_label_dict,\n",
    "            col_key_to_col_label_dict = sub_table_col_key_to_col_label_dict,\n",
    "            rows_to_highlight = rows_to_highlight,\n",
    "            col_label_prefix = col_label_prefix,\n",
    "            col_label_suffix = col_label_suffix,\n",
    "            highlight_color = highlight_color\n",
    "        )\n",
    "\n",
    "        table_str += sub_table_str + \"\\n\\n\"\n",
    "\n",
    "    return table_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nll_dict = {}\n",
    "error_nll_dict = {}\n",
    "\n",
    "col_key_to_label_dict = {}\n",
    "\n",
    "for key in path_dict.keys():\n",
    "\n",
    "    assert(f\"Evaluation_{model_to_eval}\" in os.listdir(path_dict[key]))\n",
    "\n",
    "    with open(os.path.join(path_dict[key],f\"Evaluation_{model_to_eval}\",\"validation_nll_dict.json\"),\"r\") as f:\n",
    "        NLL_dict_key = json.load(f)\n",
    "    f.close()\n",
    "\n",
    "    nll_dict[key] = NLL_dict_key[\"nll\"]\n",
    "    error_nll_dict[key] = NLL_dict_key[\"error\"]\n",
    "\n",
    "    for col_key in nll_dict[key].keys():\n",
    "        kappa_col = col_key.split('_')[0].split(\"=\")[1]\n",
    "        col_key_to_label_dict[col_key] = f\"$\\kappa = {kappa_col}$\"\n",
    "\n",
    "table_str_validation_nll = get_table_str(\n",
    "    rows_to_highlight=[\"TRADE_no_grid\",\"TRADE_grid\"],\n",
    "    rows_error_dict=error_nll_dict,\n",
    "    rows_value_dict=nll_dict,\n",
    "    row_key_to_row_label_dict=labels_dict,\n",
    "    col_key_to_col_label_dict=col_key_to_label_dict\n",
    ")\n",
    "\n",
    "with open(os.path.join(figure_folder,f\"{EXPERIMENT_MODE}_table_validation_NLL.txt\"),\"w\") as f:\n",
    "    f.write(table_str_validation_nll)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the effective sampling size:\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_ESS,ax_ESS = plt.subplots(1,1,figsize = (7,5))\n",
    "\n",
    "colors = mplt.colormaps['Set1'].colors\n",
    "counter = 0\n",
    "\n",
    "for key in path_dict.keys():\n",
    "\n",
    "    print(key)\n",
    "\n",
    "    assert(f\"Evaluation_{model_to_eval}\" in os.listdir(path_dict[key]))\n",
    "\n",
    "    # Load the spin distributions\n",
    "    ESS_r_key = np.loadtxt(os.path.join(path_dict[key],f\"Evaluation_{model_to_eval}\",\"ESS_r.txt\"))\n",
    "\n",
    "    ax_ESS.errorbar(\n",
    "        x = ESS_r_key[:,0],\n",
    "        y = ESS_r_key[:,1],\n",
    "        yerr = ESS_r_key[:,2],\n",
    "        label = labels_dict[key],\n",
    "        capsize = 3,\n",
    "        marker = \".\",\n",
    "        ls = \"dotted\",\n",
    "        color = colors[counter]\n",
    "    )\n",
    "\n",
    "    counter += 1\n",
    "\n",
    "ax_ESS.hlines(y = 1.0,xmin = ESS_r_key[:,0].min() - 0.002,xmax = ESS_r_key[:,0].max() + 0.002,ls = \"dotted\",color = \"k\",label = \"optimum\")\n",
    "\n",
    "ax_ESS.set_xlabel(r\"$\\kappa$\",fontsize = fs)\n",
    "ax_ESS.set_ylabel(r\"ESS($\\kappa$)\",fontsize = fs)\n",
    "ax_ESS.tick_params(axis='both', which='major', labelsize=fs)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "handles, labels = [], []\n",
    "\n",
    "for handle, label in zip(*ax_ESS.get_legend_handles_labels()):\n",
    "    handles.append(handle)\n",
    "    labels.append(label)\n",
    "\n",
    "# Add a single legend below all subplots\n",
    "fig_ESS.legend(handles, labels, loc='upper center', bbox_to_anchor=(0.5, 0.05), ncol=4,fontsize = fs)\n",
    "\n",
    "plt.savefig(\n",
    "        os.path.join(figure_folder,f\"{EXPERIMENT_MODE}_ESS_r.pdf\"),\n",
    "        bbox_inches='tight'\n",
    ")\n",
    "plt.savefig(\n",
    "        os.path.join(figure_folder,f\"{EXPERIMENT_MODE}_ESS_r.jpeg\"),\n",
    "        bbox_inches='tight'\n",
    ")\n",
    "plt.close(fig_ESS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the physical observables\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data_dict = {}\n",
    "\n",
    "for key in path_dict.keys():\n",
    "        data_key = np.loadtxt(os.path.join(path_dict[key],f\"Evaluation_{model_to_eval}\",\"summary_phyiscs_properties_lambda_0.02.txt\"),skiprows=1)\n",
    "        data_dict[key] = data_key\n",
    "\n",
    "\n",
    "property_cols = {\n",
    "        \"action\":3,\n",
    "        \"magnetization\":1,\n",
    "        \"binder_cumulant\":7,\n",
    "        \"susceptibility\":5,\n",
    "}\n",
    "\n",
    "reference_cols = {\n",
    "        \"action\":3,\n",
    "        \"magnetization\":1,\n",
    "        \"binder_cumulant\":5,\n",
    "        \"susceptibility\":7,\n",
    "}\n",
    "\n",
    "y_labels = {\n",
    "        \"action\":r\"$\\left<s(\\kappa)\\right>$\",\n",
    "        \"magnetization\":r\"$\\left<|m(\\kappa)|\\right>$\",\n",
    "        \"binder_cumulant\":r\"$U_L(\\kappa)$\",\n",
    "        \"susceptibility\":r\"$\\chi^2$\",\n",
    "}\n",
    "\n",
    "# Get the reference simulation\n",
    "reference = np.loadtxt(f\"../../data/ScalarTheory/validation_data/N_{N}_LANGEVIN_SPECIFIC/summary_lambda_0.02_0.txt\",skiprows = 1)\n",
    "\n",
    "steps_size = 4\n",
    "\n",
    "for property in property_cols.keys():\n",
    "\n",
    "        fig_i,ax_i = plt.subplots(1,1,figsize = (7,3.0))\n",
    "\n",
    "        colors = mplt.colormaps['Set1'].colors\n",
    "        counter = 0\n",
    "\n",
    "        ax_i.set_xlabel(r\"$\\kappa$\",fontsize = fs)\n",
    "        ax_i.set_ylabel(y_labels[property],fontsize = fs)\n",
    "        ax_i.tick_params(axis='both', which='major', labelsize=fs)\n",
    "\n",
    "        mask = (reference[:,0] <=  data_dict[key][:,0].max())\n",
    "\n",
    "        ax_i.errorbar(\n",
    "                x = reference[:,0][mask],\n",
    "                y = reference[:,reference_cols[property]][mask],\n",
    "                yerr = reference[:,reference_cols[property]+1][mask],\n",
    "                label = \"MCMC\",\n",
    "                capsize = 3,\n",
    "                marker = \".\",\n",
    "                ls = \"dotted\",\n",
    "                color = \"k\"\n",
    "        )\n",
    "\n",
    "        for key in path_dict.keys():\n",
    "                ax_i.errorbar(\n",
    "                        x = data_dict[key][:,0][::steps_size],\n",
    "                        y = data_dict[key][:,property_cols[property]][::steps_size],\n",
    "                        yerr = data_dict[key][:,property_cols[property]+1][::steps_size],\n",
    "                        label = labels_dict[key],\n",
    "                        capsize = 3,\n",
    "                        marker = \".\",\n",
    "                        ls = \"dotted\",\n",
    "                        color = colors[counter]\n",
    "                )\n",
    "\n",
    "                counter += 1\n",
    "        if property == \"susceptibility\":\n",
    "                ax_i.set_ylim([lim_susceptibility[EXPERIMENT_MODE][0],lim_susceptibility[EXPERIMENT_MODE][1]])\n",
    "\n",
    "        if property == \"binder_cumulant\":\n",
    "                ax_i.set_ylim([lim_binder[EXPERIMENT_MODE][0],lim_binder[EXPERIMENT_MODE][1]])\n",
    "        \n",
    "        ax_i.set_xlim([data_dict[key][:,0].min() - 0.005,data_dict[key][:,0].max() + 0.005])\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        handles, labels = [], []\n",
    "\n",
    "        for handle, label in zip(*ax_i.get_legend_handles_labels()):\n",
    "                handles.append(handle)\n",
    "                labels.append(label)\n",
    "\n",
    "        # Add a single legend below all subplots\n",
    "        fig_i.legend(handles, labels, loc='upper center', bbox_to_anchor=(0.5, 0.05), ncol=3,fontsize = fs)\n",
    "\n",
    "        plt.savefig(\n",
    "                os.path.join(figure_folder,f\"{EXPERIMENT_MODE}_{property}.pdf\"),\n",
    "                bbox_inches='tight'\n",
    "        )\n",
    "        plt.savefig(\n",
    "                os.path.join(figure_folder,f\"{EXPERIMENT_MODE}_{property}.jpeg\"),\n",
    "                bbox_inches='tight'\n",
    "        )\n",
    "        plt.close(fig_i)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the spin distributions of the INN\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(3,2,figsize = (13,12))\n",
    "\n",
    "axes_flat = axes.reshape(-1)\n",
    "\n",
    "fs = 20\n",
    "\n",
    "for q,key in enumerate(path_dict.keys()):\n",
    "\n",
    "    print(key)\n",
    "     \n",
    "    assert(f\"Evaluation_{model_to_eval}\" in os.listdir(path_dict[key]))\n",
    "\n",
    "    if key == \"TRADE_no_grid\":\n",
    "\n",
    "        #Get the ground truth spins_validation_data.txt\n",
    "        spins_target = np.loadtxt(os.path.join(path_dict[key],f\"Evaluation_{model_to_eval}\",\"spins_validation_data.txt\"))\n",
    "\n",
    "        kappas_list = [float(a) for a in header.split('\\t')[1:]]\n",
    "\n",
    "        cmap = get_cmap('viridis')\n",
    "        colors = [cmap(i / len(kappas_list)) for i in range(len(kappas_list))]\n",
    "\n",
    "        for i in range(1,spins_target.shape[-1]):\n",
    "            axes_flat[0].stairs(edges = spins_target[:,0],values=spins_target[:-1,i],color = colors[i-1],label = r\"$\\kappa = $\"+f\"{kappas_list[i-1]}\",lw = 2)\n",
    "\n",
    "        axes_flat[0].set_xlabel(r\"$\\phi(x)$\",fontsize = fs)\n",
    "        axes_flat[0].set_ylabel(r\"$p(\\phi(x)$)\",fontsize = fs)\n",
    "        axes_flat[0].tick_params(axis='both', which='major', labelsize=fs)\n",
    "        axes_flat[0].set_title(\"validation data\",fontsize = fs)\n",
    "\n",
    "    \n",
    "    #Load the spin distributions\n",
    "    spins_key = np.loadtxt(os.path.join(path_dict[key],f\"Evaluation_{model_to_eval}\",\"spins_INN_data.txt\"))\n",
    "\n",
    "    with open(os.path.join(path_dict[key],f\"Evaluation_{model_to_eval}\",\"spins_INN_data.txt\"),\"r\") as f:\n",
    "        header = f.readline()\n",
    "    f.close()\n",
    "\n",
    "    kappas_list = [float(a) for a in header.split('\\t')[1:]]\n",
    "\n",
    "    cmap = get_cmap('viridis')\n",
    "    colors = [cmap(i / len(kappas_list)) for i in range(len(kappas_list))]\n",
    "\n",
    "    for i in range(1,spins_key.shape[-1]):\n",
    "        axes_flat[q+1].stairs(edges = spins_key[:,0],values=spins_key[:-1,i],color = colors[i-1],label = r\"$\\kappa = $\"+f\"{kappas_list[i-1]}\",lw = 2)\n",
    "\n",
    "    axes_flat[q+1].set_xlabel(r\"$\\phi(x)$\",fontsize = fs)\n",
    "    axes_flat[q+1].set_ylabel(r\"$p(\\phi(x)$)\",fontsize = fs)\n",
    "    axes_flat[q+1].tick_params(axis='both', which='major', labelsize=fs)\n",
    "    axes_flat[q+1].set_title(labels_dict[key],fontsize = fs)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "handles, labels = [], []\n",
    "\n",
    "for handle, label in zip(*axes_flat[0].get_legend_handles_labels()):\n",
    "        handles.append(handle)\n",
    "        labels.append(label)\n",
    "\n",
    "if N == 16:\n",
    "    axes_flat[-1].get_xaxis().set_ticks([])\n",
    "    axes_flat[-1].get_yaxis().set_ticks([])\n",
    "    axes_flat[-1].axis(\"off\")\n",
    "# Add a single legend below all subplots\n",
    "fig.legend(handles, labels, loc='upper center', bbox_to_anchor=(0.5,-0.01), ncol=5,fontsize = fs)\n",
    "\n",
    "\n",
    "plt.savefig(\n",
    "    os.path.join(figure_folder,f\"{EXPERIMENT_MODE}_spin_distributions_combined.pdf\"),\n",
    "    bbox_inches='tight'\n",
    ")\n",
    "plt.close(fig_i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the performance for different random seeds:\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ESS\n",
    "fig_ESS,ax_ESS = plt.subplots(3,1,figsize = (13,5 * 3))\n",
    "\n",
    "colors = mplt.colormaps['Set1'].colors\n",
    "counter = 0\n",
    "fs = 20\n",
    "min_val = 1.0\n",
    "\n",
    "for counter,key in enumerate( folder_dict_random_seeds.keys()):\n",
    "\n",
    "    Ess_tensor_key = None\n",
    "\n",
    "    # Load all the experiments in the folder\n",
    "    for subfolder in os.listdir(folder_dict_random_seeds[key]):\n",
    "\n",
    "        assert(f\"Evaluation_{model_to_eval}\" in os.listdir(os.path.join(folder_dict_random_seeds[key],subfolder)))\n",
    "\n",
    "        ESS_r_key_i = np.loadtxt(os.path.join(folder_dict_random_seeds[key],subfolder,f\"Evaluation_{model_to_eval}\",\"ESS_r.txt\"))\n",
    "\n",
    "        if Ess_tensor_key is None:\n",
    "            Ess_tensor_key = ESS_r_key_i[:,1].reshape(-1,1)\n",
    "\n",
    "        else:\n",
    "            Ess_tensor_key = np.concatenate((Ess_tensor_key,ESS_r_key_i[:,1].reshape(-1,1)),1)\n",
    "\n",
    "    means_i= Ess_tensor_key.mean(-1)\n",
    "    std_i = Ess_tensor_key.std(-1)\n",
    "\n",
    "    ax_ESS[counter].plot(ESS_r_key_i[:,0],means_i,label = r\"$\\left<ESS\\right>$\",color = colors[counter],lw = 3)\n",
    "    ax_ESS[counter].fill_between(ESS_r_key_i[:,0],means_i - std_i,means_i + std_i,color = colors[counter],alpha = 0.3,label = r\"$\\left<ESS\\right>\\pm std(ESS)$\")\n",
    "\n",
    "    ax_ESS[counter].hlines(y = 1.0,xmin = ESS_r_key_i[:,0].min() - 0.002,xmax = ESS_r_key_i[:,0].max() + 0.002,ls = \"dotted\",color = \"k\",label = \"optimum\",lw = 3)\n",
    "\n",
    "    ax_ESS[counter].set_xlabel(r\"$\\kappa$\",fontsize = fs)\n",
    "    ax_ESS[counter].set_ylabel(r\"ESS($\\kappa$)\",fontsize = fs)\n",
    "    ax_ESS[counter].tick_params(axis='both', which='major', labelsize=fs)\n",
    "\n",
    "    if min_val > np.min(means_i - std_i):\n",
    "        min_val = np.min(means_i - std_i)\n",
    "\n",
    "    ax_ESS[counter].set_title(labels_dict[key],fontsize = fs)\n",
    "\n",
    "    ax_ESS[counter].legend(fontsize = fs)\n",
    "\n",
    "    counter += 1\n",
    "\n",
    "for counter,key in enumerate( folder_dict_random_seeds.keys()):\n",
    "    ax_ESS[counter].set_ylim([min_val - 0.01,1.1])\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\n",
    "        os.path.join(figure_folder,f\"{EXPERIMENT_MODE}_ESS_r_random_seeds.pdf\"),\n",
    "        bbox_inches='tight'\n",
    ")\n",
    "plt.close(fig_ESS)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pinf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
